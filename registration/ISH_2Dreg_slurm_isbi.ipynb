{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03eb3c25-4062-4ee2-b371-a7cdfcd5429c",
   "metadata": {},
   "source": [
    "# An automated pipeline to create an atlas of in-situ hybridization gene expression data in the adult marmoset brain (ISBI 2023, Poon, C., et al.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1560d645-0f57-427c-a460-37cf24210da8",
   "metadata": {},
   "source": [
    "## 2D registration code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fc2834-8a2b-4542-8b6c-c32af1a3ef99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib as mpl\n",
    "import sys\n",
    "sys.path.append(\"/disk/soft/SLURM/slurm/\")\n",
    "from slurm import slurm_tools\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from PIL import Image, ImageFile\n",
    "import cv2\n",
    "import time\n",
    "from scipy import ndimage, misc\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from skimage import exposure\n",
    "import skimage\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "dpi_default = mpl.rcParams['figure.dpi']\n",
    "from skimage.transform import resize, rescale\n",
    "from skimage.exposure import equalize_adapthist, equalize_hist, rescale_intensity\n",
    "import scipy\n",
    "import imageio\n",
    "\n",
    "def json_write(data,filename):\n",
    "        with open(filename, 'w') as data_file:\n",
    "            json.dump(data, data_file, indent=4, sort_keys=True, separators=(',', ':'))\n",
    "\n",
    "def json_read(filename):\n",
    "        if (os.path.isfile(filename)):\n",
    "            with open(filename) as data_file:\n",
    "                data = json.load(data_file)\n",
    "            isfile=True;\n",
    "        else:\n",
    "            data={}\n",
    "            isfile=False;\n",
    "        return data, isfile\n",
    "\n",
    "def imresize(arr,size, resample=0):   \n",
    "    if resample == Image.NEAREST:\n",
    "        interpolation = cv2.INTER_NEAREST\n",
    "    if resample == Image.LANCZOS:\n",
    "        interpolation = cv2.INTER_LANCZOS4\n",
    "    if resample == Image.BICUBIC:\n",
    "        interpolation = cv2.INTER_CUBIC\n",
    "    if resample == Image.LINEAR:\n",
    "        interpolation = cv2.INTER_LINEAR\n",
    "\n",
    "    size_ = size.copy()\n",
    "    size_[1], size_[0] = size_[0],size_[1]\n",
    "    return cv2.resize(arr,(size[1],size[0]),interpolation=interpolation)\n",
    "\n",
    "def cmp2indx(cm,ind=None):\n",
    "    if ind is None:\n",
    "        cm_ = cm.split(\"/\")[-1].replace(\".png\",\"\").split(\"_\")\n",
    "        section = int(cm_[0])\n",
    "        cmp = int(cm_[1])\n",
    "    else:\n",
    "        cmp = ind\n",
    "        section = cm\n",
    "    return (cmp-1)*12+(section-1)\n",
    "\n",
    "def indx2cmp(ind):\n",
    "    cmp = ind % 12 + 1\n",
    "    i = ind // 12 + 1\n",
    "    return \"{:02d}_{:02d}\".format(cmp,i)\n",
    "\n",
    "\n",
    "\n",
    "print(cmp2indx(\"01_03\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af91c91b-cddc-45e7-8d2c-10be0c15b43e",
   "metadata": {},
   "source": [
    "### 1. Make blockface MIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2158c80b-460b-4819-98af-169234427df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. reading in bf images #\n",
    "\n",
    "\"\"\"goal: determine actual bb of bf image\n",
    "sort them (might be not necessary)\n",
    "compute mean intensity projection\"\"\"\n",
    "\n",
    "def make_bf_mip(bf_files):   \n",
    "    \n",
    "    print(\"----- in 1 make_bf_mip for mid: \"+mid)\n",
    "    \n",
    "    bf_indx = np.argsort([cmp2indx(f) for f in bf_files])\n",
    "    bf_files_ = [bf_files[a] for a in bf_indx]\n",
    "\n",
    "    init = True\n",
    "    for f in bf_files_:\n",
    "\n",
    "        img = imageio.imread(f).mean(axis=2)/255.0\n",
    "        mask = imageio.imread(f.replace(\"blockface_raw2\",\"blockface_mask2\"))[...,0]>0\n",
    "\n",
    "        if init:\n",
    "            init = False\n",
    "            img_ = np.zeros(img.shape)\n",
    "        img_ += mask*img\n",
    "        \n",
    "        # char addition to increase intensity of cerebellum\n",
    "        if int(f.split('_')[-1].split('.')[0]) > 60:\n",
    "            img_ += mask*img*2\n",
    "\n",
    "    img_mip = img_ / len(bf_files_)\n",
    "    \n",
    "    plt.imshow(img_mip, vmin=0, vmax=1)\n",
    "    plt.title('img_mip')\n",
    "    plt.show()\n",
    "    \n",
    "    return(bf_files_, img_mip)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab13f01-4b4a-4aee-8021-6deff12ef38b",
   "metadata": {},
   "source": [
    "### 2. Make 3D blockface stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a98ad0-252d-4145-b772-a29d50a5ea63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. \n",
    "def create_bf_3d_stack(mu_bf, bf_files_, img_mip):\n",
    "    \n",
    "    print(\"----- in 2 create_bf_3d_stack for mid: \"+mid)\n",
    "    \n",
    "    pad_size = 100\n",
    "    # pad size of BF images \n",
    "    target_res = 25\n",
    "    # target resolution of bf images\n",
    "\n",
    "    valid_mask = img_mip>0.05  #char changed, 0.2\n",
    "    crop_y = np.argwhere(valid_mask.max(axis=0)>0.5)[[0,-1]]\n",
    "    crop_x = np.argwhere(valid_mask.max(axis=1)>0.5)[[0,-1]]\n",
    "\n",
    "    bf_scale = mu_bf/target_res\n",
    "\n",
    "    valid_mask_cropped = valid_mask[crop_x[0][0]:crop_x[1][0],crop_y[0][0]:crop_y[1][0]]\n",
    "    new_shape = (np.array(valid_mask_cropped.shape)*bf_scale).astype(np.int32)\n",
    "\n",
    "    cropped_mask = imresize(valid_mask_cropped.astype(np.float32),new_shape)\n",
    "    \n",
    "    plt.imshow(cropped_mask)\n",
    "    plt.show()\n",
    "    cropped_mask = np.pad(cropped_mask,[pad_size,pad_size])\n",
    "\n",
    "    if True:\n",
    "        for findx,f in zip(range(len(bf_files_)),bf_files_):\n",
    "            img = imageio.imread(f).mean(axis=2)/255.0\n",
    "            mask = imageio.imread(f.replace(\"blockface_raw2\",\"blockface_mask2\"))[...,0]>0\n",
    "\n",
    "            img = equalize_adapthist(img)#[:,:,None]\n",
    "            tmp = (img*mask)[crop_x[0][0]:crop_x[1][0],crop_y[0][0]:crop_y[1][0]]\n",
    "            img_t = imresize(tmp,new_shape)\n",
    "            img_t = np.pad(img_t,[pad_size,pad_size])*cropped_mask\n",
    "\n",
    "            if findx == 0:\n",
    "                img_3D = np.zeros([img_t.shape[0],img_t.shape[1],len(bf_files_)],dtype=np.uint8)\n",
    "            img_3D[:,:,findx] = (img_t*255).astype(np.uint8)\n",
    "\n",
    "    return img_3D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8267eb0a-9e08-4c76-b758-a62128c1b1a9",
   "metadata": {},
   "source": [
    "### 3. Filter and write blockface images as niftis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12f3f6f-720d-47a0-a5b4-f0c7d1bfc408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. \n",
    "def filter_write_bf(img_3D, target_res, bf_files_, mid):\n",
    "    \n",
    "    print(\"----- in 3 filter_write_bf for mid: \"+mid)\n",
    "    \n",
    "    bf_dir = workdir+mid+\"/bf/\"\n",
    "\n",
    "    mpl.rcParams['figure.dpi'] = dpi_default \n",
    "    plt.imshow(img_3D.max(axis=1)>0)\n",
    "    plt.savefig(mid+'.png')\n",
    "    plt.show()\n",
    "    #mpl.rcParams['figure.dpi'] = dpi_default\n",
    "    img_3D_ = scipy.ndimage.median_filter(img_3D,[3,3,7])\n",
    "    plt.imshow(img_3D_.max(axis=1)>0)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    for findx,f in zip(range(len(bf_files_)),bf_files_):\n",
    "        mat = np.eye(4)\n",
    "        mat[0,0] = target_res\n",
    "        mat[1,1] = target_res\n",
    "\n",
    "        tmp = img_3D_[:,:,findx]\n",
    "        tmp = tmp[:,:,None]\n",
    "\n",
    "        new_image = nib.Nifti1Image(tmp[:,:,0], affine=mat)\n",
    "        new_image.header.set_xyzt_units(2)\n",
    "        new_image.header[\"dim\"][0] = 2\n",
    "        new_image.header[\"sform_code\"] = 1\n",
    "        new_image.header[\"pixdim\"][4:] = 0\n",
    "        nib.save(new_image,bf_dir+\"/img_\"+str(findx+10000)+\".nii.gz\") \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5697a02-5df9-4dfc-a90a-c5a5c4cb37d8",
   "metadata": {},
   "source": [
    "### 4. Create niftis of backlit and gene images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf5d2b9-80d9-43e3-9eee-00d6fdba3d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. \n",
    "def create_bl_gene_niis(mid):\n",
    "    \n",
    "    print(\"----- in 4 create_bl_gene_niis for mid: \"+mid)\n",
    "    \n",
    "    target_res_mi = target_res\n",
    "    intensity_t = 0.2\n",
    "\n",
    "    sdir = db+mid+\"/img2d/\"\n",
    "    cmpnt = glob.glob(sdir+\"/compartments/*_*\")\n",
    "    cmpnt.sort()\n",
    "    #print(cmpnt)\n",
    "    stack = []\n",
    "    for c in cmpnt:\n",
    "        cds = c.split(\"/\")[-1]                           # component name (eg, 02_gene)\n",
    "        cds_name = cds.split('_')[-1]                    # component name (eg, gene) \n",
    "        print(cds)\n",
    "        cdi = int(cds.split(\"_\")[0])                     # component number (eg, 2)\n",
    "        img_fn = glob.glob(c+\"/*.png\")\n",
    "        img_fn.sort()\n",
    "        o_dir = workdir+mid+\"/\"+cds\n",
    "        os.makedirs(o_dir,exist_ok=True)\n",
    "        #print('o_dir:', o_dir)\n",
    "        \n",
    "        for f in img_fn:\n",
    "            \n",
    "            if \"backlit\" in cds_name:\n",
    "                #continue\n",
    "                #break\n",
    "                continue\n",
    "                print('in backlit')\n",
    "                img = imageio.imread(f)\n",
    "                bl_scale = mu_bl/target_res_mi\n",
    "                #new_shape = (np.array(img.shape)*bl_scale).astype(np.int32)\n",
    "                #img_t = imresize(img,new_shape,Image.LINEAR)\n",
    "                img_t = rescale(img, bl_scale, anti_aliasing=True)\n",
    "                #img_t = equalize_adapthist(img_t)\n",
    "                \n",
    "                img_t = np.min(img_t,axis=2)\n",
    "\n",
    "\n",
    "                mask = skimage.morphology.remove_small_objects(img_t<intensity_t,16)\n",
    "                mask = skimage.morphology.binary_dilation(mask,np.ones([15,15]))\n",
    "                white = np.maximum(np.maximum(np.maximum(img_t[0,0],img_t[-1,-1]),img_t[0,-1]),img_t[-1,0])\n",
    "                img_t[mask] = white\n",
    "\n",
    "                w_scale = 1.0/(white-intensity_t)\n",
    "                #print(w_scale)\n",
    "                #w_offset = 1.0-white\n",
    "                img_t = np.maximum(np.minimum((img_t-intensity_t)*w_scale,1.0),0.0)\n",
    "                #img_t /= 1.0 - \n",
    "            \n",
    "                \n",
    "\n",
    "                if True:\n",
    "                    mat = np.eye(4)\n",
    "                    mat[0,0] = target_res_mi\n",
    "                    mat[1,1] = target_res_mi\n",
    "                    if True:\n",
    "                        pass\n",
    "                    else:\n",
    "                        new_img = np.zeros(bl_shape)\n",
    "                        c_shape = np.array(img_t.shape[:2])\n",
    "                        new_img[...] = np.maximum(np.maximum(np.maximum(img_t[0,0],img_t[-1,-1]),img_t[0,-1]),img_t[-1,0])#np.max(np.maximum(np.maximum(np.maximum(img[0,0,:],img[-1,-1,:]),img[0,-1,0]),img[-1,0,:]))\n",
    "                        offset = (bl_shape-c_shape)//2\n",
    "                        new_img[offset[0]:offset[0]+c_shape[0],offset[1]:offset[1]+c_shape[1]] = img_t#[...,0]\n",
    "                        img_t = new_img \n",
    "\n",
    "\n",
    "                    new_image = nib.Nifti1Image(img_t, affine=mat)\n",
    "                else:\n",
    "                    mat = np.eye(3)\n",
    "                    mat[0,0] = target_res_mi\n",
    "                    mat[1,1] = target_res_mi\n",
    "                    #break\n",
    "                    img_t = equalize_adapthist(img_t)\n",
    "                    img_t = (img_t*255).astype(np.uint8)\n",
    "                    #img_t = np.maximum(img_t.max()-img_t,0)\n",
    "\n",
    "                    new_image = nib.Nifti1Image(img_t, affine=mat)\n",
    "\n",
    "                new_image.header.set_xyzt_units(2)\n",
    "                new_image.header[\"dim\"][0] = 2\n",
    "                new_image.header[\"sform_code\"] = 1\n",
    "                new_image.header[\"pixdim\"][4:] = 0\n",
    "\n",
    "                s_id = int(f.split(\"/\")[-1].replace(\".png\",\"\"))\n",
    "                bl_index = cmp2indx(cdi,s_id+1)\n",
    "                nib.save(new_image,o_dir+\"/img_\"+str(10000+bl_index)+\".nii.gz\") \n",
    "\n",
    "            else:\n",
    "\n",
    "                img = imageio.imread(f)\n",
    "                bl_scale = mu_bl/target_res_mi\n",
    "                new_shape = (np.array(img.shape)*bl_scale).astype(np.int32)\n",
    "\n",
    "                img_r = rescale(img[...,0], bl_scale, anti_aliasing=True)\n",
    "                img_g = rescale(img[...,1], bl_scale, anti_aliasing=True)\n",
    "                img_b = rescale(img[...,2], bl_scale, anti_aliasing=True)\n",
    "                img_t = np.concatenate((img_r[...,None],img_g[...,None],img_b[...,None]),axis=2)\n",
    "                #img_t = img_t*1\n",
    "                #print('img_t:', img_t.shape, img_t.dtype)\n",
    "                \n",
    "                \n",
    "                if True:  # char adaptation\n",
    "                    gray = cv2.cvtColor(img_t.astype(np.float32), cv2.COLOR_BGR2GRAY)\n",
    "                    thresh = threshold_triangle(gray)\n",
    "                    binary = gray < thresh\n",
    "                    eroded = skimage.morphology.dilation(binary)\n",
    "\n",
    "\n",
    "                    # connected component analysis\n",
    "                    nb, output, stats, centroids = cv2.connectedComponentsWithStats(eroded.astype(np.uint8), 4)\n",
    "\n",
    "                    meanvali = np.where(stats[:,-1] > stats[:,-1].mean())\n",
    "\n",
    "                    for i in range(len(meanvali[0])-1):    \n",
    "                        componentMask = (output == meanvali[0][i+1]).astype(\"uint8\") * 255\n",
    "                        print(componentMask.shape)\n",
    "                        if i==0:\n",
    "                            componentMask_all = componentMask\n",
    "                        else:\n",
    "                            componentMask_all = np.add(componentMask_all,componentMask)\n",
    "                    img_r[componentMask_all==0]=img_r[componentMask_all==0].mean()\n",
    "                    img_g[componentMask_all==0]=img_g[componentMask_all==0].mean()\n",
    "                    img_b[componentMask_all==0]=img_b[componentMask_all==0].mean()\n",
    "                    img_t = np.concatenate((img_r[...,None],img_g[...,None],img_b[...,None]),axis=2)\n",
    "                    \n",
    "                    if int(f.split('/')[-1][:-4]) % 10 == 0:\n",
    "                        plt.imshow(img_t)\n",
    "                        plt.title('img_t')\n",
    "                        plt.show()\n",
    "\n",
    "                        plt.imshow(img_t, cmap='gray')\n",
    "                        plt.title('result')\n",
    "                        plt.show()\n",
    "                \n",
    "                \n",
    "                if False:  # original\n",
    "                    img_t_g = np.min(img_t,axis=2)\n",
    "                    mask = skimage.morphology.remove_small_objects(img_t_g<intensity_t,16)\n",
    "                    mask = skimage.morphology.binary_dilation(mask,np.ones([15,15]))\n",
    "                    mask = (mask*(1-(img_b>img_g)))>0.5                                                # henrik addition sept 2022\n",
    "                    mask_rgb = np.concatenate((mask[...,None],mask[...,None],mask[...,None]),axis=2)\n",
    "                    img_t[mask] = np.maximum(np.maximum(np.maximum(img_t[0,0],img_t[-1,-1]),img_t[0,-1]),img_t[-1,0])\n",
    "\n",
    "                if False:\n",
    "                    new_shape = np.maximum(np.array(img_t.shape[:2]),bl_shape)\n",
    "                    new_img = np.zeros([new_shape[0],new_shape[1],3])\n",
    "                    c_shape = np.array(img_t.shape[:2])\n",
    "                    new_img[...] = np.max(np.maximum(np.maximum(np.maximum(img_t[0,0,:],img_t[-1,-1,:]),img_t[0,-1,:]),img_t[-1,0,:]))\n",
    "                    offset = (new_shape-c_shape)//2\n",
    "                    new_img[offset[0]:offset[0]+c_shape[0],offset[1]:offset[1]+c_shape[1],:] = img_t\n",
    "                    img_t = new_img \n",
    "\n",
    "                mat = np.eye(4)\n",
    "                mat[0,0] = target_res_mi\n",
    "                mat[1,1] = target_res_mi\n",
    "\n",
    "\n",
    "                for r in [\"R\",\"G\",\"B\",\"\",\"RGB\"]:  # \n",
    "                    if r == \"\":\n",
    "                        img_g = np.min(img_t,axis=2)\n",
    "                        new_image = nib.Nifti1Image(img_g, affine=mat)\n",
    "                        new_image.header[\"dim\"][0] = 2\n",
    "                    if r == \"R\":\n",
    "                        img_g = img_t[...,0]\n",
    "                        new_image = nib.Nifti1Image(img_g, affine=mat)\n",
    "                        new_image.header[\"dim\"][0] = 2\n",
    "                    if r == \"G\":\n",
    "                        img_g = img_t[...,1]\n",
    "                        new_image = nib.Nifti1Image(img_g, affine=mat)\n",
    "                        new_image.header[\"dim\"][0] = 2\n",
    "                    if r == \"B\":\n",
    "                        img_g = img_t[...,2]\n",
    "                        new_image = nib.Nifti1Image(img_g, affine=mat)\n",
    "                        new_image.header[\"dim\"][0] = 2\n",
    "                    if r == \"RGB\":\n",
    "                        img_g = img_t\n",
    "                        new_image = nib.Nifti1Image(img_g, affine=mat)\n",
    "                        new_image.header[\"dim\"][0] = 3\n",
    "\n",
    "                    new_image.header.set_xyzt_units(2)\n",
    "                    new_image.header[\"sform_code\"] = 1\n",
    "                    new_image.header[\"pixdim\"][4:] = 0\n",
    "                    #break\n",
    "                    s_id = int(f.split(\"/\")[-1].replace(\".png\",\"\"))\n",
    "                    bl_index = cmp2indx(cdi,s_id+1)\n",
    "\n",
    "                    nib.save(new_image,o_dir+\"/img\"+r+\"_\"+str(10000+bl_index)+\".nii.gz\") \n",
    "                    #print('saved'+o_dir+\"/img\"+r+\"_\"+str(10000+bl_index)+\".nii.gz\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df64f19-192d-4f56-b59c-5a68ceafaf84",
   "metadata": {},
   "source": [
    "### 5. Create niftis of segmented gene images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1b2a62-4bed-438f-b8d7-55450b4aff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. \n",
    "def create_geneseg_niis(mid):\n",
    "    \n",
    "    print(\"----- in 5 create_geneseg_niis for mid: \"+mid)\n",
    "    \n",
    "    target_res_mi = target_res\n",
    "    intensity_t = 0.2\n",
    "\n",
    "    sdir = db+mid+\"/img2d/\"\n",
    "    cmpnt = glob.glob(sdir+\"/compartments_mask/*_*\")  # <--\n",
    "    cmpnt.sort()\n",
    "    #print(cmpnt)\n",
    "    stack = []\n",
    "    for c in cmpnt:\n",
    "        cds = c.split(\"/\")[-1]\n",
    "        cds_name = cds.split('_')[-1]\n",
    "        #print('cds:',cds)\n",
    "        cdi = int(cds.split(\"_\")[0])\n",
    "        #input('Continue?')\n",
    "        img_fn = glob.glob(c+\"/*.png\")\n",
    "        img_fn.sort()\n",
    "        o_dir = workdir+mid+\"/\"+cds+'_seg'  # <--\n",
    "        os.makedirs(o_dir,exist_ok=True)\n",
    "        for f in img_fn:\n",
    "\n",
    "            img = imageio.imread(f)\n",
    "            bl_scale = mu_bl/target_res_mi\n",
    "            new_shape = (np.array(img.shape)*bl_scale).astype(np.int32)\n",
    "            \n",
    "            img_r = rescale(img[...], bl_scale, anti_aliasing=True)\n",
    "            img_g = rescale(img[...], bl_scale, anti_aliasing=True)\n",
    "            img_b = rescale(img[...], bl_scale, anti_aliasing=True)\n",
    "            img_t = np.concatenate((img_r[...,None],img_g[...,None],img_b[...,None]),axis=2)\n",
    "            #img_t = img_t*1\n",
    "            img_t_g = np.min(img_t,axis=2)\n",
    "            \n",
    "\n",
    "            mat = np.eye(4)\n",
    "            mat[0,0] = target_res_mi\n",
    "            mat[1,1] = target_res_mi\n",
    "\n",
    "\n",
    "            for r in [\"R\",\"G\",\"B\",\"\"]:\n",
    "                if r == \"\":\n",
    "                    img_g = np.min(img_t,axis=2)\n",
    "                if r == \"R\":\n",
    "                    img_g = img_t[...]\n",
    "                if r == \"G\":\n",
    "                    img_g = img_t[...]\n",
    "                if r == \"B\":\n",
    "                    img_g = img_t[...]\n",
    "                new_image = nib.Nifti1Image(img_g, affine=mat)\n",
    "\n",
    "                new_image.header.set_xyzt_units(2)\n",
    "                new_image.header[\"dim\"][0] = 2\n",
    "                new_image.header[\"sform_code\"] = 1\n",
    "                new_image.header[\"pixdim\"][4:] = 0\n",
    "                #break\n",
    "                s_id = int(f.split(\"/\")[-1].replace(\".png\",\"\"))\n",
    "                bl_index = cmp2indx(cdi,s_id+1)\n",
    "\n",
    "                nib.save(new_image,o_dir+\"/img\"+r+\"_\"+str(10000+bl_index)+\".nii.gz\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bb4509-5258-49e8-81a1-f56677cf91b1",
   "metadata": {},
   "source": [
    "### 6. Align backlit images to blockfaces images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17513b86-e6c1-4166-8e72-e4f7677a0810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Create aligned backlit image stack\n",
    "def align_bl(mid):\n",
    "    \n",
    "    print(\"----- in 6 align_bl for mid: \"+mid)\n",
    "    \n",
    "    cmp = \"01_backlit\"\n",
    "    cmp_dir = workdir+mid+\"/\"+cmp+\"/\"\n",
    "\n",
    "    bf_dir = workdir+mid+\"/bf/\"\n",
    "    backlit_files = glob.glob(cmp_dir+\"/*.nii.gz\")\n",
    "    backlit_files.sort()\n",
    "    bl_ids = np.array([int(c.split(\"/\")[-1].replace(\"img_\",\"\").replace(\".nii.gz\",\"\")) for c in backlit_files])\n",
    "\n",
    "    jobids=[] \n",
    "    for state in range(11): \n",
    "        print('state:', state)\n",
    "        logfolder = workdir+mid+\"/logs/\"+str(cmp)+\"/\"+str(state)+'/'\n",
    "        os.makedirs(logfolder,exist_ok=True)\n",
    "        odir = workdir+mid+\"/out/\"+str(cmp)+\"/\"+str(state)+'/'\n",
    "        os.makedirs(odir,exist_ok=True)\n",
    "        odir_prev = workdir+mid+\"/out/\"+str(cmp)+\"/\"+str(state-1)+'/'\n",
    "        os.makedirs(odir+\"/trafo/\",exist_ok=True)\n",
    "        os.makedirs(odir+\"/img/\",exist_ok=True)\n",
    "\n",
    "        for z,dind in zip(range(len(bl_ids)),bl_ids):\n",
    "            bf_img = bf_dir+\"img_\"+str(dind)+\".nii.gz\"\n",
    "            assert(os.path.isfile(bf_img))\n",
    "            nid = np.argmin(np.abs(bl_ids - dind))\n",
    "            if nid-1>=0:\n",
    "                prev_bl = bl_ids[nid-1]\n",
    "            else:\n",
    "                prev_bl = bl_ids[nid+1]\n",
    "            nearest_bl = bl_ids[nid]\n",
    "            if (nid+1) > (len(bl_ids)-1):\n",
    "                next_bl = prev_bl\n",
    "            else:\n",
    "                next_bl = bl_ids[nid+1]\n",
    "\n",
    "            FNAME  = \"img_\"+str(dind)\n",
    "\n",
    "            clear_output(wait=True)\n",
    "\n",
    "            if state == 0:\n",
    "                bl_img_0 = bf_img#cmp_dir+\"img_\"+str(prev_bl)+\".nii.gz\"\n",
    "                bl_img_1 = cmp_dir+\"img_\"+str(nearest_bl)+\".nii.gz\"\n",
    "                bl_img_2 = bf_img#cmp_dir+\"img_\"+str(next_bl)+\".nii.gz\"\n",
    "                PRETRAFO = \"[\"+bf_img+\",\"+bl_img_1+\",0]\"\n",
    "                assert(os.path.isfile(bl_img_0))\n",
    "                assert(os.path.isfile(bl_img_1))\n",
    "                assert(os.path.isfile(bl_img_2))\n",
    "            else:\n",
    "                PRETRAFO = odir_prev+\"/trafo/trafo_\"+FNAME+\"Composite.h5\"\n",
    "                bl_img_1 = cmp_dir+\"img_\"+str(nearest_bl)+\".nii.gz\"\n",
    "                bl_img_0 = odir_prev+\"/img/img_\"+str(prev_bl)+\".nii.gz\"\n",
    "                bl_img_2 = odir_prev+\"/img/img_\"+str(next_bl)+\".nii.gz\"\n",
    "                bl_avg = odir_prev+\"/filterd/img_\"+str(nearest_bl)+\".nii.gz\"\n",
    "                if z>len(bl_ids)//2:\n",
    "                    REF_BL = bl_img_0\n",
    "                else:\n",
    "                    REF_BL = bl_img_2\n",
    "\n",
    "                assert(os.path.isfile(bl_img_0))\n",
    "                assert(os.path.isfile(bl_img_1))\n",
    "                assert(os.path.isfile(bl_img_2))\n",
    "\n",
    "            SLURM_commands = [\"PRETRAFO=\"+PRETRAFO+\" STATE=\"+str(state)+\"  ODIR=\"+odir+\"  FNAME=\"+FNAME+\"  BF=\"+bf_img+\" BL1=\"+bl_img_1+\"  BL0=\"+bl_img_0+\"  BL2=\"+bl_img_2+\" bash regme_avg1.sh;\"]\n",
    "\n",
    "            if state>0:\n",
    "                SLURM_commands = [\"FIL=\"+bl_avg+\" REF_BL=\"+REF_BL+\" PRETRAFO=\"+PRETRAFO+\"  STATE=\"+str(state)+\"  ODIR=\"+odir+\"  FNAME=\"+FNAME+\"  BF=\"+bf_img+\" BL1=\"+bl_img_1+\"  BL0=\"+bl_img_0+\"  BL2=\"+bl_img_2+\" bash regme_avg2.sh;\"]#\n",
    "\n",
    "            if state>2:\n",
    "                odir_prev_affine = workdir+mid+\"/out/\"+str(cmp)+\"/\"+str(2)+'/'\n",
    "                PRETRAFO = odir_prev_affine+\"/trafo/trafo_\"+FNAME+\"Composite.h5\"\n",
    "                SLURM_commands = [\"FIL=\"+bl_avg+\" REF_BL=\"+REF_BL+\" PRETRAFO=\"+PRETRAFO+\"  STATE=\"+str(state)+\"  ODIR=\"+odir+\"  FNAME=\"+FNAME+\"  BF=\"+bf_img+\" BL1=\"+bl_img_1+\"  BL0=\"+bl_img_0+\"  BL2=\"+bl_img_2+\" bash regme_avg2_3.sh;\"]#\n",
    "\n",
    "\n",
    "            if state>4:\n",
    "                SLURM_commands = [\"FIL=\"+bl_avg+\" REF_BL=\"+REF_BL+\" PRETRAFO=\"+PRETRAFO+\"  STATE=\"+str(state)+\"  ODIR=\"+odir+\"  FNAME=\"+FNAME+\"  BF=\"+bf_img+\" BL1=\"+bl_img_1+\"  BL0=\"+bl_img_0+\"  BL2=\"+bl_img_2+\" bash regme_avg2_4.sh;\"]#\n",
    "\n",
    "\n",
    "            jobid, success = slurm_tools.slurm_submit(SLURM_commands,\n",
    "                name = str(state)+\" \"+str(dind),\n",
    "                output = logfolder+'/log'+str(dind)+'.out',\n",
    "                mem = '16GB',\n",
    "                cores = '10',\n",
    "                partition = \"ish-adult\",#\"bigmem\",\n",
    "                #nodelist = 'bigmem-02',                                      \n",
    "                )      \n",
    "\n",
    "            print(\"job number: \"+jobid)\n",
    "\n",
    "            if not success:\n",
    "                    print(\"could not submit jobs\")\n",
    "                    print(format(jobid))\n",
    "                    print(format(jobids))\n",
    "                    slurm_tools.killall(jobids)\n",
    "            jobids.append(int(jobid))\n",
    "           # break\n",
    "\n",
    "        print(\"state \"+str(state))\n",
    "        slurm_tools.wait_for_jobs(jobids)\n",
    "\n",
    "\n",
    "        time.sleep(5)\n",
    "        if True:\n",
    "                for z,dind in zip(range(len(bl_ids)),bl_ids):\n",
    "                        nid = np.argmin(np.abs(bl_ids - dind))\n",
    "                        nearest_bl = bl_ids[nid]\n",
    "\n",
    "                        FNAME  = \"img_\"+str(dind)\n",
    "\n",
    "                        odir = workdir+mid+\"/out/\"+str(cmp)+\"/\"+str(state)+'/'\n",
    "                        bl_img_1 = odir+\"/img/img_\"+str(nearest_bl)+\".nii.gz\"\n",
    "                        assert(os.path.isfile(bl_img_1))\n",
    "\n",
    "                        data = nib.load(bl_img_1)\n",
    "                        if z == 0:\n",
    "                            img_3d = np.zeros([data.shape[0],data.shape[1],len(bl_ids)])\n",
    "                        img_3d[...,z] = data.get_fdata(dtype=np.float32)#*255\n",
    "\n",
    "                if state<2:\n",
    "                    img_3ds = skimage.filters.gaussian(img_3d,[3,3,7],mode='constant',cval=1)            \n",
    "                elif state <5:\n",
    "                    img_3ds = skimage.filters.gaussian(img_3d,[3,3,5],mode='constant',cval=1)            \n",
    "                else:\n",
    "                    img_3ds = skimage.filters.gaussian(img_3d,[3,3,3],mode='constant',cval=1)            \n",
    "                img_3ds = (img_3ds+np.flip(img_3ds,axis=1))/2.0\n",
    "\n",
    "\n",
    "                odir_f = workdir+mid+\"/out/\"+str(cmp)+\"/\"+str(state)+'/filterd/'\n",
    "                os.makedirs(odir_f,exist_ok=True)\n",
    "                for z,dind in zip(range(len(bl_ids)),bl_ids):\n",
    "                    nid = np.argmin(np.abs(bl_ids - dind))\n",
    "                    nearest_bl = bl_ids[nid]\n",
    "\n",
    "                    odir = workdir+mid+\"/out/\"+str(cmp)+\"/\"+str(state)+'/'\n",
    "                    bl_img_1 = odir+\"/img/img_\"+str(nearest_bl)+\".nii.gz\"\n",
    "\n",
    "                    assert(os.path.isfile(bl_img_1))\n",
    "                    data_ref = nib.load(bl_img_1)\n",
    "\n",
    "                    bl_img_1 = odir_f+\"/img_\"+str(nearest_bl)+\".nii.gz\"\n",
    "\n",
    "                    img_t = img_3ds[...,z]\n",
    "\n",
    "                    new_image = nib.Nifti1Image(img_t, affine=data_ref.affine)\n",
    "\n",
    "                    new_image.header.set_xyzt_units(2)\n",
    "                    new_image.header[\"dim\"][0] = 2\n",
    "                    new_image.header[\"sform_code\"] = 1\n",
    "                    new_image.header[\"pixdim\"][4:] = 0\n",
    "                    nib.save(new_image,bl_img_1) \n",
    "                    print('bl_img_1:', bl_img_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81913531-0545-46f9-b664-f39f0e4d7a5d",
   "metadata": {},
   "source": [
    "### 7. Align raw ISH images to blockface and backlit images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d5a207-e270-4315-835e-64f976b03da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Create aligned ish raw\n",
    "def align_ish(mid, cmp_list):\n",
    "\n",
    "    print(\"----- in 7 align_ish for mid: \"+mid)\n",
    "    workdir = '/disk/charissa/ISH_reg_pipeline/data/'\n",
    "    mid = 'R04_0239'\n",
    "\n",
    "    bl_fil = workdir+mid+\"/out/01_backlit/10/filterd/\"  #'/01_backlit/'\n",
    "    bl_fil_f = sorted(glob.glob(bl_fil+'*.nii.gz'))\n",
    "\n",
    "    cmp_plus = os.listdir(workdir+mid)\n",
    "    cmp_ls = [x for x in cmp_plus if '_gene' in x and 'seg' not in x]\n",
    "    cmp_ls = sorted(cmp_ls)\n",
    "    cmp_ls\n",
    "\n",
    "    #cmp = \"02_gene\"\n",
    "\n",
    "    for cmp in cmp_ls:  #[\"07\",\"10\"]:  # [\"02\",\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\",\"10\",\"11\",\"12\"]\n",
    "        cmp_dir = workdir+mid+\"/\"+cmp+\"/\"\n",
    "        cmp_f = sorted(glob.glob(cmp_dir+'img_*.nii.gz'))\n",
    "        print('{} in {}'.format(len(cmp_f),cmp))\n",
    "\n",
    "\n",
    "        bf_dir = workdir+mid+\"/bf/\"  # \"/bl/\"  charissa changed this\n",
    "        backlit_files = glob.glob(cmp_dir+\"/img_*.nii.gz\")\n",
    "        backlit_files.sort()\n",
    "        bl_ids = np.array([int(c.split(\"/\")[-1].replace(\"img_\",\"\").replace(\".nii.gz\",\"\")) for c in backlit_files])\n",
    "\n",
    "\n",
    "\n",
    "        jobids=[]  \n",
    "        for state in [0]:#,1,2]:\n",
    "            for z in range(len(cmp_f)):\n",
    "                cmp_nom = cmp_f[z].split('/')[-2]\n",
    "                FNAME = cmp_f[z].split('/')[-1]\n",
    "\n",
    "                # make dirs\n",
    "                odir = workdir+mid+\"/out/\"+cmp_nom+\"/\"+str(state)+'/'\n",
    "                os.makedirs(odir, exist_ok=True)\n",
    "                odir_im = odir+'/img/'\n",
    "                os.makedirs(odir_im, exist_ok=True)\n",
    "                odir_trafo = odir+'/trafo/'\n",
    "                os.makedirs(odir_trafo, exist_ok=True)\n",
    "                logfolder = odir+'/log_ish2blstate'+str(state)+'/'\n",
    "                os.makedirs(logfolder, exist_ok=True)\n",
    "\n",
    "                OUT = odir_im+FNAME\n",
    "                POSTTRAFO = odir_trafo+'trafo_'+FNAME[:-7]+\"Composite.h5\"\n",
    "\n",
    "                move_n = cmp_f[z]\n",
    "                fixed_n = bl_fil_f[z]\n",
    "\n",
    "                print(\"cmp:{}, \\nbl:{}\".format(cmp_f[z], bl_fil_f[z]))\n",
    "\n",
    "                clear_output(wait=True)\n",
    "\n",
    "                #os.system(\"sbatch %(POSTTRAFO, OUT, fixed_n, move_n))\n",
    "\n",
    "                SLURM_commands = [\"PRETRAFO=\"+PRETRAFO+\"  STATE=\"+str(state)+\"  ODIR=\"+odir+\"  FNAME=\"+FNAME+\"  BF=\"+bf_img+\" BL1=\"+bl_img_1+\"  BL0=\"+bl_img_0+\"  BL2=\"+bl_img_2+\" bash regme_gene_01.sh;\"]\n",
    "                if state == 0:\n",
    "                    SLURM_commands = [\"FIL=\"+bl_avg+\" REF_BL=\"+REF_BL+\" PRETRAFO=\"+PRETRAFO+\"  STATE=\"+str(state)+\"  ODIR=\"+odir+\"  FNAME=\"+FNAME+\"  BF=\"+bf_img+\" BL1=\"+bl_img_1+\"  BL0=\"+bl_img_0+\"  BL2=\"+bl_img_2+\" bash regme_gene_02.sh;\"]#\n",
    "\n",
    "                if state>0:\n",
    "                    SLURM_commands = [\"FIL=\"+bl_avg+\" REF_BL=\"+REF_BL+\" PRETRAFO=\"+PRETRAFO+\"  STATE=\"+str(state)+\"  ODIR=\"+odir+\"  FNAME=\"+FNAME+\"  BF=\"+bf_img+\" BL1=\"+bl_img_1+\"  BL0=\"+bl_img_0+\"  BL2=\"+bl_img_2+\" bash regme_gene_02.sh;\"]#\n",
    "\n",
    "\n",
    "                if state>1:\n",
    "                    odir_prev_affine = workdir+mid+\"/out/\"+str(cmp)+\"/\"+str(1)+'/'\n",
    "                    PRETRAFO = odir_prev_affine+\"/trafo/trafo_\"+FNAME+\"Composite.h5\"\n",
    "                    SLURM_commands = [\"FIL=\"+bl_avg+\" REF_BL=\"+REF_BL+\" PRETRAFO=\"+PRETRAFO+\"  STATE=\"+str(state)+\"  ODIR=\"+odir+\"  FNAME=\"+FNAME+\"  BF=\"+bf_img+\" BL1=\"+bl_img_1+\"  BL0=\"+bl_img_0+\"  BL2=\"+bl_img_2+\" bash regme_gene_03.sh;\"]#\n",
    "\n",
    "                    \n",
    "                    \n",
    "                jobids=[]\n",
    "                jobid, success = slurm_tools.slurm_submit(SLURM_commands,\n",
    "                    name = str(state)+\" \"+FNAME,\n",
    "                    output = logfolder+'/log'+FNAME+'.out',\n",
    "                    mem = '256GB',\n",
    "                    cores = '48',\n",
    "                    partition = \"ish-adult\",\n",
    "                    time=\"UNLIMITED\",\n",
    "                    )      \n",
    "\n",
    "                print(\"job number: \"+jobid)\n",
    "\n",
    "                if not success:\n",
    "                        print(\"could not submit jobs\")\n",
    "                        print(format(jobid))\n",
    "                        print(format(jobids))\n",
    "                        slurm_tools.killall(jobids)\n",
    "                jobids.append(int(jobid))\n",
    "               # break\n",
    "\n",
    "\n",
    "                slurm_tools.wait_for_jobs(jobids)\n",
    "\n",
    "\n",
    "\n",
    "            print(\"state \"+str(state))\n",
    "            slurm_tools.wait_for_jobs(jobids)\n",
    "        save_filterd_niis(odir_im, state)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17254578-86b8-4611-a3ac-a01d817a3a58",
   "metadata": {},
   "source": [
    "### 8. Align segmented ISH images based on transforms from aligning raw ISH images in step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f25d80d-3fe4-4710-8b61-b4979e63a706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Create aligned ish seg\n",
    "def align_ish_seg(mid, cmp_ls):\n",
    "    \n",
    "    print(\"----- in 8 align_ish_seg for mid: \"+mid)\n",
    "    \n",
    "    ref_cmp = \"01_backlit\"\n",
    "    ref_cmp_dir = workdir+mid+\"/\"+ref_cmp+\"/\"\n",
    "    ref_files = glob.glob(ref_cmp_dir+\"/*.nii.gz\")\n",
    "    ref_files.sort()\n",
    "    ref_bl_ids = np.array([int(c.split(\"/\")[-1].replace(\"img_\",\"\").replace(\".nii.gz\",\"\")) for c in ref_files])\n",
    "\n",
    "    for cmp in cmp_ls:  \n",
    "        cmp_dir = workdir+mid+\"/\"+cmp+\"/\"\n",
    "        print('cmp_dir:',cmp_dir)\n",
    "\n",
    "        bf_dir = workdir+mid+\"/bf/\"  \n",
    "        backlit_files = glob.glob(cmp_dir+\"/img_*.nii.gz\")\n",
    "        backlit_files.sort()\n",
    "        bl_ids = np.array([int(c.split(\"/\")[-1].replace(\"img_\",\"\").replace(\".nii.gz\",\"\")) for c in backlit_files])\n",
    "\n",
    "        jobids=[]  \n",
    "\n",
    "        state=1\n",
    "        logfolder = workdir+mid+\"/logs/\"+str(cmp)+\"/\"+str(state)+'/'\n",
    "        os.makedirs(logfolder,exist_ok=True)\n",
    "        odir = workdir+mid+\"/out_seg/\"+str(cmp)+\"/\"+str(state)+'/'\n",
    "        print('odir: ', odir)\n",
    "        os.makedirs(odir,exist_ok=True)\n",
    "        odir_prev = workdir+mid+\"/out_seg/\"+str(cmp)+\"/\"+str(state-1)+'/'\n",
    "        dir_trafo = workdir+mid+\"/out/\"+str(cmp).split('_seg')[0]+\"/\"+str(2)+'/'\n",
    "        print('str(cmp): ',str(cmp))\n",
    "        print('dir_trafo: ',dir_trafo)\n",
    "\n",
    "        os.makedirs(odir+\"/trafo/\",exist_ok=True)\n",
    "        os.makedirs(odir+\"/img/\",exist_ok=True)\n",
    "\n",
    "        if True:\n",
    "            for z,dind in zip(range(len(bl_ids)),bl_ids):\n",
    "                bf_img = bf_dir+\"img_\"+str(dind)+\".nii.gz\"\n",
    "                assert(os.path.isfile(bf_img))\n",
    "\n",
    "                nid = np.argmin(np.abs(bl_ids - dind))      \n",
    "                if nid-1>=0:\n",
    "                    prev_bl = bl_ids[nid-1]\n",
    "                else:\n",
    "                    prev_bl = bl_ids[nid+1]\n",
    "                nearest_bl = bl_ids[nid]\n",
    "                if (nid+1) > (len(bl_ids)-1):\n",
    "                    next_bl = prev_bl\n",
    "                else:\n",
    "                    next_bl = bl_ids[nid+1]\n",
    "\n",
    "                nid = np.argmin(np.abs(ref_bl_ids - dind))  \n",
    "                nearest_ref = ref_bl_ids[nid]\n",
    "\n",
    "                FNAME  = \"img_\"+str(dind)\n",
    "\n",
    "                clear_output(wait=True)\n",
    "\n",
    "                odir_ref = workdir+mid+\"/out/01_backlit/10/\"\n",
    "                print('odir_ref: ',odir_ref)\n",
    "\n",
    "                bf_img = odir_ref+\"/filterd/\"+\"img_\"+str(nearest_ref)+\".nii.gz\"  # not used\n",
    "\n",
    "                bl_img_1 = cmp_dir+\"img_\"+str(nearest_bl)+\".nii.gz\"\n",
    "                bl_img_0 = cmp_dir+\"img_\"+str(prev_bl)+\".nii.gz\"\n",
    "                bl_img_2 = cmp_dir+\"img_\"+str(next_bl)+\".nii.gz\"\n",
    "                bl_avg = odir_ref+\"/filterd/img_\"+str(nearest_bl)+\".nii.gz\"\n",
    "                if z>len(bl_ids)//2:\n",
    "                    REF_BL = bl_img_0\n",
    "                else:\n",
    "                    REF_BL = bl_img_2\n",
    "\n",
    "                assert(os.path.isfile(bl_img_0))\n",
    "                assert(os.path.isfile(bl_img_1))\n",
    "                assert(os.path.isfile(bl_img_2))\n",
    "\n",
    "                PRETRAFO = dir_trafo+\"/trafo/trafo_\"+FNAME+\"Composite.h5\"\n",
    "                print('dir_trafo: ',dir_trafo)\n",
    "                print('FNAME: ',FNAME)\n",
    "                print('PRETRAFO: ', PRETRAFO)\n",
    "                SLURM_commands = [\"FIL=\"+bl_avg+\" REF_BL=\"+REF_BL+\" PRETRAFO=\"+PRETRAFO+\"  STATE=\"+str(state)+\"  ODIR=\"+odir+\"  FNAME=\"+FNAME+\"  BF=\"+bf_img+\" BL1=\"+bl_img_1+\"  BL0=\"+bl_img_0+\"  BL2=\"+bl_img_2+\" bash regme_gene_03_seg.sh;\"]#\n",
    "\n",
    "                jobid, success = slurm_tools.slurm_submit(SLURM_commands,\n",
    "                    name = str(state)+\" \"+str(dind),\n",
    "                    output = logfolder+'/log'+str(dind)+'.out',\n",
    "                    mem = '16GB',\n",
    "                    cores = '10',\n",
    "                    nodelist = 'bigmem-02',                                      \n",
    "                    )      \n",
    "\n",
    "                print(\"job number: \"+jobid)\n",
    "\n",
    "                if not success:\n",
    "                        print(\"could not submit jobs\")\n",
    "                        print(format(jobid))\n",
    "                        print(format(jobids))\n",
    "                        slurm_tools.killall(jobids)\n",
    "                jobids.append(int(jobid))\n",
    "\n",
    "            print(\"state \"+str(state))\n",
    "            slurm_tools.wait_for_jobs(jobids)\n",
    "\n",
    "\n",
    "        # to make filtered images/stack\n",
    "        if True:\n",
    "            time.sleep(5)\n",
    "            #state = 0\n",
    "            for z,dind in zip(range(len(bl_ids)),bl_ids):\n",
    "\n",
    "                nid = np.argmin(np.abs(bl_ids - dind))\n",
    "                nearest_bl = bl_ids[nid]\n",
    "\n",
    "                FNAME  = \"img_\"+str(dind)\n",
    "\n",
    "                odir = workdir+mid+\"/out_seg/\"+str(cmp)+\"/\"+str(state)+'/'\n",
    "                os.makedirs(odir,exist_ok=True)\n",
    "                #bl_img_1 = cmp_dir+\"img_\"+str(nearest_bl)+\".nii.gz\"\n",
    "                bl_img_1 = odir+\"/img/img_\"+str(nearest_bl)+\".nii.gz\"\n",
    "                assert(os.path.isfile(bl_img_1))\n",
    "\n",
    "                data = nib.load(bl_img_1)\n",
    "                if z == 0:\n",
    "                    img_3d = np.zeros([data.shape[0],data.shape[1],len(bl_ids)])\n",
    "                img_3d[...,z] = data.get_fdata(dtype=np.float32)#*255\n",
    "\n",
    "            img_3ds = skimage.filters.gaussian(img_3d,[3,3,3],mode='constant',cval=1)            \n",
    "            img_3ds = (img_3ds+np.flip(img_3ds,axis=1))/2.0\n",
    "\n",
    "\n",
    "            odir_f = workdir+mid+\"/out_seg/\"+str(cmp)+\"/\"+str(state)+'/filterd/'\n",
    "            os.makedirs(odir_f,exist_ok=True)\n",
    "            for z,dind in zip(range(len(bl_ids)),bl_ids):\n",
    "\n",
    "                nid = np.argmin(np.abs(bl_ids - dind))\n",
    "                nearest_bl = bl_ids[nid]\n",
    "\n",
    "                odir = workdir+mid+\"/out_seg/\"+str(cmp)+\"/\"+str(state)+'/'\n",
    "                bl_img_1 = odir+\"/img/img_\"+str(nearest_bl)+\".nii.gz\"\n",
    "                assert(os.path.isfile(bl_img_1))\n",
    "                data_ref = nib.load(bl_img_1)\n",
    "\n",
    "                bl_img_1 = odir_f+\"/img_\"+str(nearest_bl)+\".nii.gz\"\n",
    "\n",
    "                #img_t = (np.minimum(np.maximum(img_3ds[...,z],0),255)).astype(np.uint8)\n",
    "                img_t = img_3ds[...,z]\n",
    "\n",
    "                new_image = nib.Nifti1Image(img_t, affine=data_ref.affine)\n",
    "\n",
    "                new_image.header.set_xyzt_units(2)\n",
    "                new_image.header[\"dim\"][0] = 2\n",
    "                new_image.header[\"sform_code\"] = 1\n",
    "                new_image.header[\"pixdim\"][4:] = 0\n",
    "                nib.save(new_image,bl_img_1) \n",
    "            time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2f34fc-bb08-44ca-adad-d909c6a68495",
   "metadata": {},
   "source": [
    "## Run 2d registration on a list of marmoset IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a05df8-ab99-4c5b-85b9-d65e8871aaf4",
   "metadata": {},
   "source": [
    "### Get a list of marmoset IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76903b0-9b69-415f-a5af-aeff699ad9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all marmoset folders with blockface images\n",
    "root = '/disk/charissa/shimogori_adult/'\n",
    "marm_ls = []\n",
    "for marm_dir in os.listdir(root):\n",
    "    if os.path.isdir(os.path.join(root, marm_dir)) and 'R0' in marm_dir:\n",
    "        if os.path.exists(os.path.join(root,marm_dir)+'/img2d/blockface_raw/'):\n",
    "            marm_ls.append(marm_dir)\n",
    "        \n",
    "marm_ls.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf454f2b-be54-4240-a55a-21d49b3312a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a random slice from each marm\n",
    "from matplotlib.pyplot import figure\n",
    "import random\n",
    "workdir = '/disk/charissa/ISH_reg_pipeline/data/'\n",
    "\n",
    "figure(figsize=(8, 6), dpi=120)\n",
    "plt.rcParams.update({'font.size': 7})\n",
    "\n",
    "for d in range(len(marm_ls)):  # \n",
    "    cdir = workdir+marm_ls[d]+'/bf/img_'+str(random.randint(10000,11000))+'.nii.gz'\n",
    "    nibo = nib.load(cdir)\n",
    "    nibim = nibo.get_fdata()\n",
    "\n",
    "    plt.subplot(5,10,d+1)\n",
    "    plt.imshow(nibim)\n",
    "    plt.title(marm_ls[d])\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('bf_masked_20220905.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca906dc0-ae79-4630-a34a-902d6a0e8251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call everything, loop try the rest of the data\n",
    "db = '/disk/charissa/shimogori_adult/'\n",
    "workdir = '/disk/charissa/ISH_reg_pipeline/data/'\n",
    "target_res = 25\n",
    "mu_bl = 3.12\n",
    "\n",
    "for d in range(len(marm_ls)):\n",
    "    \n",
    "    mid = marm_ls[d]\n",
    "    print(mid)\n",
    "\n",
    "    mu_bl = 3.12\n",
    "    mu_bf = 28.72\n",
    "\n",
    "    print(\"mu bl:\",mu_bl)\n",
    "    print(\"mu bf:\",mu_bf)\n",
    "\n",
    "    os.makedirs(workdir+mid+\"/bf/\",exist_ok=True)\n",
    "\n",
    "    sdir = db+mid+\"/img2d/\"\n",
    "    bf_files = glob.glob(sdir+\"/blockface_raw2/*.png\")\n",
    "    bf_files.sort()\n",
    "    \n",
    "    bf_files_, img_mip = make_bf_mip(bf_files)  # 1\n",
    "    img_3D = create_bf_3d_stack(mu_bf, bf_files_, img_mip)  # 2\n",
    "    filter_write_bf(img_3D, target_res, bf_files_, mid)  # 3\n",
    "    create_bl_gene_niis(mid)  # 4\n",
    "    create_geneseg_niis(mid)  # 5\n",
    "    \n",
    "\n",
    "    cmp_ls_all = os.listdir(workdir+mid)\n",
    "    cmp_ls_raw = [m for m in cmp_ls_all if 'gene' in m and 'backlit' not in m and 'seg' not in m]\n",
    "    cmp_ls_seg = [m for m in cmp_ls_all if 'gene_seg' in m and 'backlit' not in m]\n",
    "    \n",
    "    align_bl(mid)  # 6\n",
    "    align_ish(mid,cmp_ls_raw)  # 7\n",
    "    align_ish_seg(mid,cmp_ls_seg)  # 8\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cluster]",
   "language": "python",
   "name": "conda-env-cluster-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
