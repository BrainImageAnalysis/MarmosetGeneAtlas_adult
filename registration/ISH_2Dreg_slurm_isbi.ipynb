{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03eb3c25-4062-4ee2-b371-a7cdfcd5429c",
   "metadata": {},
   "source": [
    "# An automated pipeline to create an atlas of in-situ hybridization gene expression data in the adult marmoset brain (ISBI 2023, Poon, C., et al.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1560d645-0f57-427c-a460-37cf24210da8",
   "metadata": {},
   "source": [
    "## 2D registration code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b1d4eb-f83a-4955-924f-3642ed5ef4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assumes the following data organization:\n",
    "├── db\n",
    "│   ├── mid1\n",
    "│   │   ├── blockface_raw\n",
    "│   │   ├── blockface_mask\n",
    "│   │   ├── img2d\n",
    "│   │   │   ├── compartments\n",
    "│   │   │   │   ├── 01_backlit\n",
    "│   │   │   │   ├── 02_gene\n",
    "│   │   │   │   ├── 03_gene\n",
    "│   │   │   │   ├── 04_gene\n",
    "│   │   │   │   ├── 05_gene\n",
    "│   │   │   │   ├── 06_gene\n",
    "│   │   │   │   ├── 07_gene\n",
    "│   │   │   │   ├── 08_gene\n",
    "│   │   │   │   ├── ...\n",
    "│   ├── mid2\n",
    "│   │   ├── blockface_raw\n",
    "│   │   ├── blockface_mask\n",
    "│   │   ├── img2d\n",
    "│   │   │   ├── compartments\n",
    "│   │   │   │   ├── backlit\n",
    "│   │   │   │   ├── 01_gene\n",
    "│   │   │   │   ├── 02_gene\n",
    "│   │   │   │   ├── ...\n",
    "\n",
    "\n",
    "db = database path, eg '/home/user/projectA'\n",
    "mid = subject name, eg 'marmoset_1'\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fc2834-8a2b-4542-8b6c-c32af1a3ef99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib as mpl\n",
    "import sys\n",
    "\n",
    "# slurm_tools is available in the BrainImageAnalysis repository\n",
    "# https://github.com/BrainImageAnalysis/slurm_tools\n",
    "sys.path.append(\"/disk/soft/SLURM/slurm/\")]\n",
    "from slurm import slurm_tools\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from PIL import Image, ImageFile\n",
    "import cv2\n",
    "import time\n",
    "from scipy import ndimage, misc\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from skimage import exposure\n",
    "import skimage\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "dpi_default = mpl.rcParams['figure.dpi']\n",
    "from skimage.transform import resize, rescale\n",
    "from skimage.exposure import equalize_adapthist, equalize_hist, rescale_intensity\n",
    "import scipy\n",
    "import imageio\n",
    "\n",
    "def json_write(data,filename):\n",
    "        with open(filename, 'w') as data_file:\n",
    "            json.dump(data, data_file, indent=4, sort_keys=True, separators=(',', ':'))\n",
    "\n",
    "def json_read(filename):\n",
    "        if (os.path.isfile(filename)):\n",
    "            with open(filename) as data_file:\n",
    "                data = json.load(data_file)\n",
    "            isfile=True;\n",
    "        else:\n",
    "            data={}\n",
    "            isfile=False;\n",
    "        return data, isfile\n",
    "\n",
    "def imresize(arr,size, resample=0):   \n",
    "    if resample == Image.NEAREST:\n",
    "        interpolation = cv2.INTER_NEAREST\n",
    "    if resample == Image.LANCZOS:\n",
    "        interpolation = cv2.INTER_LANCZOS4\n",
    "    if resample == Image.BICUBIC:\n",
    "        interpolation = cv2.INTER_CUBIC\n",
    "    if resample == Image.LINEAR:\n",
    "        interpolation = cv2.INTER_LINEAR\n",
    "\n",
    "    size_ = size.copy()\n",
    "    size_[1], size_[0] = size_[0],size_[1]\n",
    "    return cv2.resize(arr,(size[1],size[0]),interpolation=interpolation)\n",
    "\n",
    "\"\"\"\n",
    "This function is specific to our file naming system \n",
    "assumes that there are multiple compartments (ie genes),\n",
    "eg \"01_03\" is the first image in the third compartment.\n",
    "If this is not relevant for your dataset, \n",
    "we have tried to provide an alternative. \n",
    "(see if True,, if False statements)\n",
    "\"\"\"\n",
    "def cmp2indx(cm,ind=None):\n",
    "    if ind is None:\n",
    "        cm_ = cm.split(\"/\")[-1].replace(\".png\",\"\").split(\"_\")\n",
    "        section = int(cm_[0])\n",
    "        cmp = int(cm_[1])\n",
    "    else:\n",
    "        cmp = ind\n",
    "        section = cm\n",
    "    return (cmp-1)*12+(section-1)\n",
    "\n",
    "def indx2cmp(ind):\n",
    "    cmp = ind % 12 + 1\n",
    "    i = ind // 12 + 1\n",
    "    return \"{:02d}_{:02d}\".format(cmp,i)\n",
    "\n",
    "\n",
    "\n",
    "print(cmp2indx(\"01_03\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af91c91b-cddc-45e7-8d2c-10be0c15b43e",
   "metadata": {},
   "source": [
    "### 1. Make blockface MIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2158c80b-460b-4819-98af-169234427df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. reading in bf images #\n",
    "\n",
    "\"\"\"\n",
    "Goal: determine actual bounding box of blockface (bf) images.\n",
    "Compute mean intensity projection.\n",
    "\n",
    "Assumes that blockfaces images (blockface_raw) have a binary mask (blockface_mask).\n",
    "\"\"\"\n",
    "\n",
    "def make_bf_mip(bf_files):   \n",
    "    \n",
    "    print(\"----- in 1 make_bf_mip for mid: \"+mid)\n",
    "    \n",
    "    if True:\n",
    "        bf_indx = np.argsort([cmp2indx(f) for f in bf_files])\n",
    "        bf_files_ = [bf_files[a] for a in bf_indx]\n",
    "    else:\n",
    "        bf_files_ = sorted(bf_files)\n",
    "\n",
    "    init = True\n",
    "    for f in bf_files_:\n",
    "\n",
    "        img = imageio.imread(f).mean(axis=2)/255.0\n",
    "        mask = imageio.imread(f.replace(\"blockface_raw\",\"blockface_mask\"))[...,0]>0\n",
    "\n",
    "        if init:\n",
    "            init = False\n",
    "            img_ = np.zeros(img.shape)\n",
    "        img_ += mask*img\n",
    "        \n",
    "        # char addition to increase intensity of cerebellum\n",
    "        if int(f.split('_')[-1].split('.')[0]) > 60:\n",
    "            img_ += mask*img*2\n",
    "\n",
    "    img_mip = img_ / len(bf_files_)\n",
    "    \n",
    "    plt.imshow(img_mip, vmin=0, vmax=1)\n",
    "    plt.title('img_mip')\n",
    "    plt.show()\n",
    "    \n",
    "    return(bf_files_, img_mip)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab13f01-4b4a-4aee-8021-6deff12ef38b",
   "metadata": {},
   "source": [
    "### 2. Make 3D blockface stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a98ad0-252d-4145-b772-a29d50a5ea63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. \n",
    "\"\"\"\n",
    "Create a 3D stack of blockface images, cropped to be the same size based on \n",
    "the blockface MIP created in step 1.\n",
    "\"\"\"\n",
    "\n",
    "def create_bf_3d_stack(mu_bf, bf_files_, img_mip):\n",
    "    \n",
    "    print(\"----- in 2 create_bf_3d_stack for mid: \"+mid)\n",
    "\n",
    "    # pad size of BF images \n",
    "    pad_size = 100\n",
    "    # target resolution of bf images\n",
    "    target_res = 25\n",
    "\n",
    "    valid_mask = img_mip>0.05  #char changed, 0.2\n",
    "    crop_y = np.argwhere(valid_mask.max(axis=0)>0.5)[[0,-1]]\n",
    "    crop_x = np.argwhere(valid_mask.max(axis=1)>0.5)[[0,-1]]\n",
    "\n",
    "    bf_scale = mu_bf/target_res\n",
    "\n",
    "    valid_mask_cropped = valid_mask[crop_x[0][0]:crop_x[1][0],crop_y[0][0]:crop_y[1][0]]\n",
    "    new_shape = (np.array(valid_mask_cropped.shape)*bf_scale).astype(np.int32)\n",
    "\n",
    "    cropped_mask = imresize(valid_mask_cropped.astype(np.float32),new_shape)\n",
    "    \n",
    "    plt.imshow(cropped_mask)\n",
    "    plt.show()\n",
    "    cropped_mask = np.pad(cropped_mask,[pad_size,pad_size])\n",
    "\n",
    "    if True:\n",
    "        for findx,f in zip(range(len(bf_files_)),bf_files_):\n",
    "            img = imageio.imread(f).mean(axis=2)/255.0\n",
    "            mask = imageio.imread(f.replace(\"blockface_raw\",\"blockface_mask\"))[...,0]>0\n",
    "\n",
    "            img = equalize_adapthist(img)#[:,:,None]\n",
    "            tmp = (img*mask)[crop_x[0][0]:crop_x[1][0],crop_y[0][0]:crop_y[1][0]]\n",
    "            img_t = imresize(tmp,new_shape)\n",
    "            img_t = np.pad(img_t,[pad_size,pad_size])*cropped_mask\n",
    "\n",
    "            if findx == 0:\n",
    "                img_3D = np.zeros([img_t.shape[0],img_t.shape[1],len(bf_files_)],dtype=np.uint8)\n",
    "            img_3D[:,:,findx] = (img_t*255).astype(np.uint8)\n",
    "\n",
    "    return img_3D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8267eb0a-9e08-4c76-b758-a62128c1b1a9",
   "metadata": {},
   "source": [
    "### 3. Filter and write blockface images as niftis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12f3f6f-720d-47a0-a5b4-f0c7d1bfc408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. \n",
    "\"\"\"\n",
    "Pass a 3D median filter over the blockface stack.\n",
    "Save the filtered 2D blockface images as niftis.\n",
    "\"\"\"\n",
    "\n",
    "def filter_write_bf(img_3D, target_res, bf_files_, mid):\n",
    "    \n",
    "    print(\"----- in 3 filter_write_bf for mid: \"+mid)\n",
    "    \n",
    "    bf_dir = workdir+mid+\"/bf/\"\n",
    "\n",
    "    mpl.rcParams['figure.dpi'] = dpi_default \n",
    "    plt.imshow(img_3D.max(axis=1)>0)\n",
    "    plt.savefig(mid+'.png')\n",
    "    plt.show()\n",
    "\n",
    "    img_3D_ = scipy.ndimage.median_filter(img_3D,[3,3,7])\n",
    "    plt.imshow(img_3D_.max(axis=1)>0)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    for findx,f in zip(range(len(bf_files_)),bf_files_):\n",
    "        mat = np.eye(4)\n",
    "        mat[0,0] = target_res\n",
    "        mat[1,1] = target_res\n",
    "\n",
    "        tmp = img_3D_[:,:,findx]\n",
    "        tmp = tmp[:,:,None]\n",
    "\n",
    "        new_image = nib.Nifti1Image(tmp[:,:,0], affine=mat)\n",
    "        new_image.header.set_xyzt_units(2)\n",
    "        new_image.header[\"dim\"][0] = 2\n",
    "        new_image.header[\"sform_code\"] = 1\n",
    "        new_image.header[\"pixdim\"][4:] = 0\n",
    "        nib.save(new_image,bf_dir+\"/img_\"+str(findx+10000)+\".nii.gz\") \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5697a02-5df9-4dfc-a90a-c5a5c4cb37d8",
   "metadata": {},
   "source": [
    "### 4. Create niftis of backlit and gene images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf5d2b9-80d9-43e3-9eee-00d6fdba3d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. \n",
    "\n",
    "\"\"\"\n",
    "Create cleaned backlit and gene nifti images.\n",
    "\"\"\"\n",
    "\n",
    "def create_bl_gene_niis(mid, img_type):\n",
    "    \n",
    "    print(\"----- in 4 create_bl_gene_niis for mid: \"+mid)\n",
    "    \n",
    "    target_res_mi = target_res\n",
    "    intensity_t = 0.2\n",
    "\n",
    "    sdir = db+mid+\"/img2d/\"\n",
    "    cmpnt = glob.glob(sdir+\"/compartments/*_*\")\n",
    "    cmpnt.sort()\n",
    "    \n",
    "    stack = []\n",
    "    for c in cmpnt:\n",
    "        cds = c.split(\"/\")[-1]                           # component name (eg, 02_gene)\n",
    "        cds_name = cds.split('_')[-1]                    # component name (eg, gene) \n",
    "        print(cds)\n",
    "        cdi = int(cds.split(\"_\")[0])                     # component number (eg, 2)\n",
    "        img_fn = glob.glob(c+\"/*.\"+img_type)\n",
    "        img_fn.sort()\n",
    "        o_dir = workdir+mid+\"/\"+cds\n",
    "        os.makedirs(o_dir,exist_ok=True)\n",
    "        \n",
    "        \n",
    "        for f in img_fn:\n",
    "            \n",
    "            # backlit images are processed different from ISH gene images\n",
    "            if \"backlit\" in cds_name:\n",
    "                print('in backlit')\n",
    "                img = imageio.imread(f)\n",
    "                bl_scale = mu_bl/target_res_mi\n",
    "                img_t = rescale(img, bl_scale, anti_aliasing=True) \n",
    "                # np.min because distinctive features have lower intensity\n",
    "                img_t = np.min(img_t,axis=2)\n",
    "\n",
    "                # remove artifacts (eg dust) from image\n",
    "                mask = skimage.morphology.remove_small_objects(img_t<intensity_t,16)\n",
    "                mask = skimage.morphology.binary_dilation(mask,np.ones([15,15]))\n",
    "                white = np.maximum(np.maximum(np.maximum(img_t[0,0],img_t[-1,-1]),img_t[0,-1]),img_t[-1,0])\n",
    "                img_t[mask] = white\n",
    "                w_scale = 1.0/(white-intensity_t)\n",
    "                img_t = np.maximum(np.minimum((img_t-intensity_t)*w_scale,1.0),0.0)           \n",
    "                \n",
    "                # save as nifti\n",
    "                mat = np.eye(4)\n",
    "                mat[0,0] = target_res_mi\n",
    "                mat[1,1] = target_res_mi\n",
    "                new_image = nib.Nifti1Image(img_t, affine=mat)\n",
    "                new_image.header.set_xyzt_units(2)\n",
    "                new_image.header[\"dim\"][0] = 2\n",
    "                new_image.header[\"sform_code\"] = 1\n",
    "                new_image.header[\"pixdim\"][4:] = 0\n",
    "\n",
    "                if True:\n",
    "                    s_id = int(f.split(\"/\")[-1].replace(\".png\",\"\"))\n",
    "                    bl_index = cmp2indx(cdi,s_id+1)\n",
    "                    nib.save(new_image,o_dir+\"/img_\"+str(10000+bl_index)+\".nii.gz\") \n",
    "                else:\n",
    "                    nib.save(new_image,o_dir+\"/img_\"+f.split('/')[-1]) \n",
    "            \n",
    "            # if gene image\n",
    "            else:\n",
    "                img = imageio.imread(f)\n",
    "                bl_scale = mu_bl/target_res_mi\n",
    "                new_shape = (np.array(img.shape)*bl_scale).astype(np.int32)\n",
    "\n",
    "                # separate image by channel and scale image\n",
    "                img_r = rescale(img[...,0], bl_scale, anti_aliasing=True)\n",
    "                img_g = rescale(img[...,1], bl_scale, anti_aliasing=True)\n",
    "                img_b = rescale(img[...,2], bl_scale, anti_aliasing=True)\n",
    "                img_t = np.concatenate((img_r[...,None],img_g[...,None],img_b[...,None]),axis=2)\n",
    "                \n",
    "                \n",
    "                # clean image\n",
    "                gray = cv2.cvtColor(img_t.astype(np.float32), cv2.COLOR_BGR2GRAY)\n",
    "                thresh = threshold_triangle(gray)\n",
    "                binary = gray < thresh\n",
    "                eroded = skimage.morphology.dilation(binary)\n",
    "                # connected component analysis\n",
    "                nb, output, stats, centroids = cv2.connectedComponentsWithStats(eroded.astype(np.uint8), 4)\n",
    "                meanvali = np.where(stats[:,-1] > stats[:,-1].mean())\n",
    "\n",
    "                for i in range(len(meanvali[0])-1):    \n",
    "                    componentMask = (output == meanvali[0][i+1]).astype(\"uint8\") * 255\n",
    "                    print(componentMask.shape)\n",
    "                    if i==0:\n",
    "                        componentMask_all = componentMask\n",
    "                    else:\n",
    "                        componentMask_all = np.add(componentMask_all,componentMask)\n",
    "                img_r[componentMask_all==0]=img_r[componentMask_all==0].mean()\n",
    "                img_g[componentMask_all==0]=img_g[componentMask_all==0].mean()\n",
    "                img_b[componentMask_all==0]=img_b[componentMask_all==0].mean()\n",
    "                img_t = np.concatenate((img_r[...,None],img_g[...,None],img_b[...,None]),axis=2)\n",
    "\n",
    "                if int(f.split('/')[-1][:-4]) % 10 == 0:\n",
    "                    plt.imshow(img_t)\n",
    "                    plt.title('img_t')\n",
    "                    plt.show()\n",
    "\n",
    "                    plt.imshow(img_t, cmap='gray')\n",
    "                    plt.title('result')\n",
    "                    plt.show()\n",
    "\n",
    "                # save images as niftis\n",
    "                mat = np.eye(4)\n",
    "                mat[0,0] = target_res_mi\n",
    "                mat[1,1] = target_res_mi\n",
    "\n",
    "\n",
    "                for r in [\"R\",\"G\",\"B\",\"\",\"RGB\"]:  # \n",
    "                    if r == \"\":\n",
    "                        img_g = np.min(img_t,axis=2)\n",
    "                        new_image = nib.Nifti1Image(img_g, affine=mat)\n",
    "                        new_image.header[\"dim\"][0] = 2\n",
    "                    if r == \"R\":\n",
    "                        img_g = img_t[...,0]\n",
    "                        new_image = nib.Nifti1Image(img_g, affine=mat)\n",
    "                        new_image.header[\"dim\"][0] = 2\n",
    "                    if r == \"G\":\n",
    "                        img_g = img_t[...,1]\n",
    "                        new_image = nib.Nifti1Image(img_g, affine=mat)\n",
    "                        new_image.header[\"dim\"][0] = 2\n",
    "                    if r == \"B\":\n",
    "                        img_g = img_t[...,2]\n",
    "                        new_image = nib.Nifti1Image(img_g, affine=mat)\n",
    "                        new_image.header[\"dim\"][0] = 2\n",
    "                    if r == \"RGB\":\n",
    "                        img_g = img_t\n",
    "                        new_image = nib.Nifti1Image(img_g, affine=mat)\n",
    "                        new_image.header[\"dim\"][0] = 3\n",
    "\n",
    "                    new_image.header.set_xyzt_units(2)\n",
    "                    new_image.header[\"sform_code\"] = 1\n",
    "                    new_image.header[\"pixdim\"][4:] = 0\n",
    "                    \n",
    "                    if True:\n",
    "                        s_id = int(f.split(\"/\")[-1].replace(\".\"+img_type,\"\"))\n",
    "                        bl_index = cmp2indx(cdi,s_id+1)\n",
    "                        nib.save(new_image,o_dir+\"/img\"+r+\"_\"+str(10000+bl_index)+\".nii.gz\") \n",
    "                    if False:\n",
    "                        nib.save(new_image,o_dir+f.split('/')[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df64f19-192d-4f56-b59c-5a68ceafaf84",
   "metadata": {},
   "source": [
    "### 5. Create niftis of segmented gene images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1b2a62-4bed-438f-b8d7-55450b4aff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. \n",
    "\"\"\"\n",
    "Create niftis of segmented gene images.\n",
    "\"\"\"\n",
    "\n",
    "def create_geneseg_niis(mid, img_type):\n",
    "    \n",
    "    print(\"----- in 5 create_geneseg_niis for mid: \"+mid)\n",
    "    \n",
    "    target_res_mi = target_res\n",
    "    intensity_t = 0.2\n",
    "\n",
    "    sdir = db+mid+\"/img2d/\"\n",
    "    cmpnt = glob.glob(sdir+\"/compartments_mask/*_*\")  # <--\n",
    "    cmpnt.sort()\n",
    "    \n",
    "    for c in cmpnt:\n",
    "        cds = c.split(\"/\")[-1]\n",
    "        cds_name = cds.split('_')[-1]\n",
    "        cdi = int(cds.split(\"_\")[0])\n",
    "        img_fn = glob.glob(c+\"/*.\"+img_type)\n",
    "        img_fn.sort()\n",
    "        o_dir = workdir+mid+\"/\"+cds+'_seg'\n",
    "        os.makedirs(o_dir,exist_ok=True)\n",
    "        for f in img_fn:\n",
    "\n",
    "            img = imageio.imread(f)\n",
    "            \n",
    "            # scale image\n",
    "            bl_scale = mu_bl/target_res_mi\n",
    "            new_shape = (np.array(img.shape)*bl_scale).astype(np.int32)\n",
    "            img_r = rescale(img[...], bl_scale, anti_aliasing=True)\n",
    "            img_g = rescale(img[...], bl_scale, anti_aliasing=True)\n",
    "            img_b = rescale(img[...], bl_scale, anti_aliasing=True)\n",
    "            img_t = np.concatenate((img_r[...,None],img_g[...,None],img_b[...,None]),axis=2)\n",
    "            img_t_g = np.min(img_t,axis=2)\n",
    "            \n",
    "            \n",
    "            # save images as niftis\n",
    "            mat = np.eye(4)\n",
    "            mat[0,0] = target_res_mi\n",
    "            mat[1,1] = target_res_mi\n",
    "\n",
    "            for r in [\"R\",\"G\",\"B\",\"\"]:\n",
    "                if r == \"\":\n",
    "                    img_g = np.min(img_t,axis=2)\n",
    "                if r == \"R\":\n",
    "                    img_g = img_t[...]\n",
    "                if r == \"G\":\n",
    "                    img_g = img_t[...]\n",
    "                if r == \"B\":\n",
    "                    img_g = img_t[...]\n",
    "                new_image = nib.Nifti1Image(img_g, affine=mat)\n",
    "\n",
    "                new_image.header.set_xyzt_units(2)\n",
    "                new_image.header[\"dim\"][0] = 2\n",
    "                new_image.header[\"sform_code\"] = 1\n",
    "                new_image.header[\"pixdim\"][4:] = 0\n",
    "\n",
    "                if True:\n",
    "                    s_id = int(f.split(\"/\")[-1].replace(\".png\",\"\"))\n",
    "                    bl_index = cmp2indx(cdi,s_id+1)\n",
    "                    nib.save(new_image,o_dir+\"/img\"+r+\"_\"+str(10000+bl_index)+\".nii.gz\") \n",
    "                else:\n",
    "                    nib.save(new_image,o_dir+\"/img\"+r+\"_\"+f.split('/')[-1]) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bb4509-5258-49e8-81a1-f56677cf91b1",
   "metadata": {},
   "source": [
    "### 6. Align backlit images to blockfaces images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17513b86-e6c1-4166-8e72-e4f7677a0810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Create aligned backlit image stack\n",
    "\n",
    "\"\"\"\n",
    "Align backlit images to blockface images in 10 iterations.\n",
    "Takes as input backlit and blockface niftis that were saved in step #4.\n",
    "Uses ANTs Normalization Toolbox and slurm.\n",
    "To be moved to ANTsPy in the near future.\n",
    "\"\"\"\n",
    "\n",
    "def align_bl(mid):\n",
    "    \n",
    "    print(\"----- in 6 align_bl for mid: \"+mid)\n",
    "    \n",
    "    cmp = \"01_backlit\"\n",
    "    cmp_dir = workdir+mid+\"/\"+cmp+\"/\"\n",
    "\n",
    "    bf_dir = workdir+mid+\"/bf/\"\n",
    "    backlit_files = glob.glob(cmp_dir+\"/*.nii.gz\")\n",
    "    backlit_files.sort()\n",
    "    bl_ids = np.array([int(c.split(\"/\")[-1].replace(\"img_\",\"\").replace(\".nii.gz\",\"\")) for c in backlit_files])\n",
    "\n",
    "    jobids=[] \n",
    "    for state in range(11): \n",
    "        print('state:', state)\n",
    "        \n",
    "        # create output directories for images and transforms\n",
    "        logfolder = workdir+mid+\"/logs/\"+str(cmp)+\"/\"+str(state)+'/'\n",
    "        os.makedirs(logfolder,exist_ok=True)\n",
    "        odir = workdir+mid+\"/out/\"+str(cmp)+\"/\"+str(state)+'/'\n",
    "        os.makedirs(odir,exist_ok=True)\n",
    "        odir_prev = workdir+mid+\"/out/\"+str(cmp)+\"/\"+str(state-1)+'/'\n",
    "        os.makedirs(odir+\"/trafo/\",exist_ok=True)\n",
    "        os.makedirs(odir+\"/img/\",exist_ok=True)\n",
    "\n",
    "        for z,dind in zip(range(len(bl_ids)),bl_ids):\n",
    "            bf_img = bf_dir+\"img_\"+str(dind)+\".nii.gz\"\n",
    "            assert(os.path.isfile(bf_img))\n",
    "            nid = np.argmin(np.abs(bl_ids - dind))\n",
    "            \n",
    "            # find the bl_ids of the previous and next backlit slices.\n",
    "            # If the current slice is the FIRST slice, then the previous slice is set to be the same as the next slice.\n",
    "            # If the current slice is the LAST slice, then the next slice is set to be the same as the previous slice.\n",
    "            if nid-1>=0:\n",
    "                prev_bl = bl_ids[nid-1]\n",
    "            else:\n",
    "                prev_bl = bl_ids[nid+1]\n",
    "            nearest_bl = bl_ids[nid]\n",
    "            if (nid+1) > (len(bl_ids)-1):\n",
    "                next_bl = prev_bl\n",
    "            else:\n",
    "                next_bl = bl_ids[nid+1]\n",
    "\n",
    "            FNAME  = \"img_\"+str(dind)\n",
    "\n",
    "            clear_output(wait=True)\n",
    "\n",
    "            if state == 0:\n",
    "                bl_img_0 = bf_img\n",
    "                bl_img_1 = cmp_dir+\"img_\"+str(nearest_bl)+\".nii.gz\"\n",
    "                bl_img_2 = bf_img\n",
    "                PRETRAFO = \"[\"+bf_img+\",\"+bl_img_1+\",0]\"\n",
    "                assert(os.path.isfile(bl_img_0))\n",
    "                assert(os.path.isfile(bl_img_1))\n",
    "                assert(os.path.isfile(bl_img_2))\n",
    "            else:\n",
    "                PRETRAFO = odir_prev+\"/trafo/trafo_\"+FNAME+\"Composite.h5\"\n",
    "                bl_img_1 = cmp_dir+\"img_\"+str(nearest_bl)+\".nii.gz\"\n",
    "                bl_img_0 = odir_prev+\"/img/img_\"+str(prev_bl)+\".nii.gz\"\n",
    "                bl_img_2 = odir_prev+\"/img/img_\"+str(next_bl)+\".nii.gz\"\n",
    "                bl_avg = odir_prev+\"/filterd/img_\"+str(nearest_bl)+\".nii.gz\"\n",
    "                if z>len(bl_ids)//2:\n",
    "                    REF_BL = bl_img_0\n",
    "                else:\n",
    "                    REF_BL = bl_img_2\n",
    "\n",
    "                assert(os.path.isfile(bl_img_0))\n",
    "                assert(os.path.isfile(bl_img_1))\n",
    "                assert(os.path.isfile(bl_img_2))\n",
    "                \n",
    "            # for state == 0\n",
    "            SLURM_commands = [\"PRETRAFO=\"+PRETRAFO+\" STATE=\"+str(state)+\"  ODIR=\"+odir+\"  FNAME=\"+FNAME+\"  BF=\"+bf_img+\" BL1=\"+bl_img_1+\"  BL0=\"+bl_img_0+\"  BL2=\"+bl_img_2+\" bash regme_avg1.sh;\"]\n",
    "\n",
    "            # for state == 1,2\n",
    "            if state>0:\n",
    "                SLURM_commands = [\"FIL=\"+bl_avg+\" REF_BL=\"+REF_BL+\" PRETRAFO=\"+PRETRAFO+\"  STATE=\"+str(state)+\"  ODIR=\"+odir+\"  FNAME=\"+FNAME+\"  BF=\"+bf_img+\" BL1=\"+bl_img_1+\"  BL0=\"+bl_img_0+\"  BL2=\"+bl_img_2+\" bash regme_avg2.sh;\"]#\n",
    "\n",
    "            # for state == 3,4\n",
    "            if state>2:\n",
    "                odir_prev_affine = workdir+mid+\"/out/\"+str(cmp)+\"/\"+str(2)+'/'\n",
    "                PRETRAFO = odir_prev_affine+\"/trafo/trafo_\"+FNAME+\"Composite.h5\"\n",
    "                SLURM_commands = [\"FIL=\"+bl_avg+\" REF_BL=\"+REF_BL+\" PRETRAFO=\"+PRETRAFO+\"  STATE=\"+str(state)+\"  ODIR=\"+odir+\"  FNAME=\"+FNAME+\"  BF=\"+bf_img+\" BL1=\"+bl_img_1+\"  BL0=\"+bl_img_0+\"  BL2=\"+bl_img_2+\" bash regme_avg2_3.sh;\"]#\n",
    "\n",
    "            # for state == 5~10\n",
    "            if state>4:\n",
    "                SLURM_commands = [\"FIL=\"+bl_avg+\" REF_BL=\"+REF_BL+\" PRETRAFO=\"+PRETRAFO+\"  STATE=\"+str(state)+\"  ODIR=\"+odir+\"  FNAME=\"+FNAME+\"  BF=\"+bf_img+\" BL1=\"+bl_img_1+\"  BL0=\"+bl_img_0+\"  BL2=\"+bl_img_2+\" bash regme_avg2_4.sh;\"]#\n",
    "\n",
    "            # submit slurm commands using slurm_tools\n",
    "            # kwargs will depend on your cluster\n",
    "            jobid, success = slurm_tools.slurm_submit(SLURM_commands,\n",
    "                name = str(state)+\" \"+str(dind),\n",
    "                output = logfolder+'/log'+str(dind)+'.out',\n",
    "                mem = '16GB',\n",
    "                cores = '10',\n",
    "                partition = \"ish-adult\",\n",
    "                )      \n",
    "\n",
    "            print(\"job number: \"+jobid)\n",
    "\n",
    "            if not success:\n",
    "                    print(\"could not submit jobs\")\n",
    "                    print(format(jobid))\n",
    "                    print(format(jobids))\n",
    "                    slurm_tools.killall(jobids)\n",
    "            jobids.append(int(jobid))\n",
    "\n",
    "        print(\"state \"+str(state))\n",
    "        slurm_tools.wait_for_jobs(jobids)\n",
    "\n",
    "        time.sleep(5)\n",
    "\n",
    "        \n",
    "        # filter and save the aligned backlit images for each state\n",
    "        for z,dind in zip(range(len(bl_ids)),bl_ids):\n",
    "                nid = np.argmin(np.abs(bl_ids - dind))\n",
    "                nearest_bl = bl_ids[nid]\n",
    "\n",
    "                FNAME  = \"img_\"+str(dind)\n",
    "\n",
    "                odir = workdir+mid+\"/out/\"+str(cmp)+\"/\"+str(state)+'/'\n",
    "                bl_img_1 = odir+\"/img/img_\"+str(nearest_bl)+\".nii.gz\"\n",
    "                assert(os.path.isfile(bl_img_1))\n",
    "\n",
    "                data = nib.load(bl_img_1)\n",
    "                if z == 0:\n",
    "                    img_3d = np.zeros([data.shape[0],data.shape[1],len(bl_ids)])\n",
    "                img_3d[...,z] = data.get_fdata(dtype=np.float32)#*255\n",
    "\n",
    "        if state<2:\n",
    "            img_3ds = skimage.filters.gaussian(img_3d,[3,3,7],mode='constant',cval=1)            \n",
    "        elif state <5:\n",
    "            img_3ds = skimage.filters.gaussian(img_3d,[3,3,5],mode='constant',cval=1)            \n",
    "        else:\n",
    "            img_3ds = skimage.filters.gaussian(img_3d,[3,3,3],mode='constant',cval=1)            \n",
    "        img_3ds = (img_3ds+np.flip(img_3ds,axis=1))/2.0\n",
    "\n",
    "\n",
    "        odir_f = workdir+mid+\"/out/\"+str(cmp)+\"/\"+str(state)+'/filterd/'\n",
    "        os.makedirs(odir_f,exist_ok=True)\n",
    "        for z,dind in zip(range(len(bl_ids)),bl_ids):\n",
    "            nid = np.argmin(np.abs(bl_ids - dind))\n",
    "            nearest_bl = bl_ids[nid]\n",
    "\n",
    "            odir = workdir+mid+\"/out/\"+str(cmp)+\"/\"+str(state)+'/'\n",
    "            bl_img_1 = odir+\"/img/img_\"+str(nearest_bl)+\".nii.gz\"\n",
    "            assert(os.path.isfile(bl_img_1))\n",
    "            \n",
    "            data_ref = nib.load(bl_img_1)\n",
    "\n",
    "            bl_img_1 = odir_f+\"/img_\"+str(nearest_bl)+\".nii.gz\"\n",
    "\n",
    "            img_t = img_3ds[...,z]\n",
    "\n",
    "            new_image = nib.Nifti1Image(img_t, affine=data_ref.affine)\n",
    "            new_image.header.set_xyzt_units(2)\n",
    "            new_image.header[\"dim\"][0] = 2\n",
    "            new_image.header[\"sform_code\"] = 1\n",
    "            new_image.header[\"pixdim\"][4:] = 0\n",
    "            nib.save(new_image,bl_img_1) \n",
    "            print('bl_img_1:', bl_img_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81913531-0545-46f9-b664-f39f0e4d7a5d",
   "metadata": {},
   "source": [
    "### 7. Align raw ISH images to backlit images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d5a207-e270-4315-835e-64f976b03da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Create aligned ish raw\n",
    "\n",
    "\"\"\"\n",
    "Align ISH gene images to backlit images in 3 iterations (states).\n",
    "Takes as input aligned backlit images and filtered aligned backlit images (both from step #6)\n",
    "and gene image niftis that were saved in step #4.\n",
    "Uses ANTs Normalization Toolbox and slurm.\n",
    "To be moved to ANTsPy in the near future.\n",
    "\"\"\"\n",
    "\n",
    "def align_ish(mid, cmp_list):\n",
    "\n",
    "    print(\"----- in 7 align_ish for mid: \"+mid)\n",
    "    \n",
    "    ref_cmp = \"01_backlit\"\n",
    "    ref_cmp_dir = workdir+mid+\"/\"+ref_cmp+\"/\"\n",
    "    ref_files = glob.glob(ref_cmp_dir+\"/*.nii.gz\")\n",
    "    ref_files.sort()\n",
    "    ref_bl_ids = np.array([int(c.split(\"/\")[-1].replace(\"img_\",\"\").replace(\".nii.gz\",\"\")) for c in ref_files])\n",
    "\n",
    "    for cmp_i in cmp_list: \n",
    "        cmp = cmp_i\n",
    "        cmp_dir = workdir+mid+\"/\"+cmp+\"/\"\n",
    "        print('cmp_dir:',cmp_dir)\n",
    "\n",
    "        # get backlit ids\n",
    "        bf_dir = workdir+mid+\"/bl/\"\n",
    "        backlit_files = glob.glob(cmp_dir+\"/img_*.nii.gz\")\n",
    "        backlit_files.sort()\n",
    "        bl_ids = np.array([int(c.split(\"/\")[-1].replace(\"img_\",\"\").replace(\".nii.gz\",\"\")) for c in backlit_files])\n",
    "\n",
    "        jobids=[]  \n",
    "        for state in [0,1,2]:\n",
    "            \n",
    "            # create output directories\n",
    "            logfolder = workdir+mid+\"/logs/\"+str(cmp)+\"/\"+str(state)+'/'\n",
    "            os.makedirs(logfolder,exist_ok=True)\n",
    "            odir = workdir+mid+\"/out/\"+str(cmp)+\"/\"+str(state)+'/'\n",
    "            odir_prev = workdir+mid+\"/out/\"+str(cmp)+\"/\"+str(state-1)+'/'\n",
    "            os.makedirs(odir+\"/trafo/\",exist_ok=True)\n",
    "            os.makedirs(odir+\"/img/\",exist_ok=True)\n",
    "\n",
    "            for z,dind in zip(range(len(bl_ids)),bl_ids):\n",
    "                bf_img = bf_dir+\"img_\"+str(dind)+\".nii.gz\"\n",
    "                assert(os.path.isfile(bf_img))\n",
    "\n",
    "                # find the bl_ids of the previous and next backlit slices.\n",
    "                # If the current slice is the FIRST slice, then the previous slice is set to be the same as the next slice.\n",
    "                # If the current slice is the LAST slice, then the next slice is set to be the same as the previous slice.                \n",
    "                nid = np.argmin(np.abs(bl_ids - dind))\n",
    "                if nid-1>=0:\n",
    "                    prev_bl = bl_ids[nid-1]\n",
    "                else:\n",
    "                    prev_bl = bl_ids[nid+1]\n",
    "                nearest_bl = bl_ids[nid]\n",
    "                if (nid+1) > (len(bl_ids)-1):\n",
    "                    next_bl = prev_bl\n",
    "                else:\n",
    "                    next_bl = bl_ids[nid+1]\n",
    "\n",
    "                nid = np.argmin(np.abs(ref_bl_ids - dind))\n",
    "                nearest_ref = ref_bl_ids[nid]\n",
    "\n",
    "                FNAME  = \"img_\"+str(dind)\n",
    "\n",
    "\n",
    "                clear_output(wait=True)\n",
    "\n",
    "                odir_ref = workdir+mid+\"/out/01_backlit/10/\"\n",
    "\n",
    "                if state == 0:\n",
    "\n",
    "                    bf_img = odir_ref+\"/filterd/\"+\"img_\"+str(nearest_ref)+\".nii.gz\"\n",
    "                    bl_img_1 = cmp_dir+\"img_\"+str(nearest_bl)+\".nii.gz\"\n",
    "                    PRETRAFO = \"[\"+bf_img+\",\"+bl_img_1+\",0]\"\n",
    "                    assert(os.path.isfile(bf_img))\n",
    "                    assert(os.path.isfile(bl_img_1))\n",
    "                else:\n",
    "                    PRETRAFO = odir_prev+\"/trafo/trafo_\"+FNAME+\"Composite.h5\"\n",
    "                    bf_img = odir_ref+\"/filterd/\"+\"img_\"+str(nearest_ref)+\".nii.gz\"\n",
    "\n",
    "                    bl_img_1 = cmp_dir+\"img_\"+str(nearest_bl)+\".nii.gz\"\n",
    "                    bl_img_0 = odir_prev+\"/img/img_\"+str(prev_bl)+\".nii.gz\"\n",
    "                    bl_img_2 = odir_prev+\"/img/img_\"+str(next_bl)+\".nii.gz\"\n",
    "                    bl_avg = odir_prev+\"/filterd/img_\"+str(nearest_bl)+\".nii.gz\"\n",
    "                    if z>len(bl_ids)//2:\n",
    "                        REF_BL = bl_img_0\n",
    "                    else:\n",
    "                        REF_BL = bl_img_2\n",
    "\n",
    "                    assert(os.path.isfile(bl_img_0))\n",
    "                    assert(os.path.isfile(bl_img_1))\n",
    "                    assert(os.path.isfile(bl_img_2))\n",
    "\n",
    "\n",
    "                SLURM_commands = [\"PRETRAFO=\"+PRETRAFO+\"  STATE=\"+str(state)+\"  ODIR=\"+odir+\"  FNAME=\"+FNAME+\"  BF=\"+bf_img+\" BL1=\"+bl_img_1+\" bash regme_gene_01.sh;\"]\n",
    "\n",
    "                if state>0:\n",
    "                    SLURM_commands = [\"FIL=\"+bl_avg+\" REF_BL=\"+REF_BL+\" PRETRAFO=\"+PRETRAFO+\"  STATE=\"+str(state)+\"  ODIR=\"+odir+\"  FNAME=\"+FNAME+\"  BF=\"+bf_img+\" BL1=\"+bl_img_1+\"  BL0=\"+bl_img_0+\"  BL2=\"+bl_img_2+\" bash regme_gene_02.sh;\"]#\n",
    "\n",
    "\n",
    "                if state>1:\n",
    "                    odir_prev_affine = workdir+mid+\"/out/\"+str(cmp)+\"/\"+str(1)+'/'\n",
    "                    PRETRAFO = odir_prev_affine+\"/trafo/trafo_\"+FNAME+\"Composite.h5\"\n",
    "                    SLURM_commands = [\"FIL=\"+bl_avg+\" REF_BL=\"+REF_BL+\" PRETRAFO=\"+PRETRAFO+\"  STATE=\"+str(state)+\"  ODIR=\"+odir+\"  FNAME=\"+FNAME+\"  BF=\"+bf_img+\" BL1=\"+bl_img_1+\"  BL0=\"+bl_img_0+\"  BL2=\"+bl_img_2+\" bash regme_gene_03.sh;\"]#\n",
    "                \n",
    "                # submit jobs to slurm\n",
    "                # kwargs will depend on your system\n",
    "                jobid, success = slurm_tools.slurm_submit(SLURM_commands,\n",
    "                    name = str(state)+\" \"+str(dind),\n",
    "                    output = logfolder+'/log'+str(dind)+'.out',\n",
    "                    mem = '16GB',\n",
    "                    cores = '10',\n",
    "                    partition = \"ish-adult\"\n",
    "                    )      \n",
    "\n",
    "                print(\"job number: \"+jobid)\n",
    "\n",
    "                if not success:\n",
    "                        print(\"could not submit jobs\")\n",
    "                        print(format(jobid))\n",
    "                        print(format(jobids))\n",
    "                        slurm_tools.killall(jobids)\n",
    "                jobids.append(int(jobid))\n",
    "\n",
    "            print(\"state \"+str(state))\n",
    "            slurm_tools.wait_for_jobs(jobids)\n",
    "\n",
    "\n",
    "\n",
    "            time.sleep(5)\n",
    "\n",
    "            # filter and aligned images and save as niftis\n",
    "            for z,dind in zip(range(len(bl_ids)),bl_ids):\n",
    "\n",
    "\n",
    "                nid = np.argmin(np.abs(bl_ids - dind))\n",
    "                nearest_bl = bl_ids[nid]\n",
    "\n",
    "                FNAME  = \"img_\"+str(dind)\n",
    "\n",
    "                odir = workdir+mid+\"/out/\"+str(cmp)+\"/\"+str(state)+'/'\n",
    "                bl_img_1 = odir+\"/img/img_\"+str(nearest_bl)+\".nii.gz\"\n",
    "                assert(os.path.isfile(bl_img_1))\n",
    "\n",
    "                data = nib.load(bl_img_1)\n",
    "                if z == 0:\n",
    "                    img_3d = np.zeros([data.shape[0],data.shape[1],len(bl_ids)])\n",
    "                img_3d[...,z] = data.get_fdata(dtype=np.float32)#*255\n",
    "\n",
    "            if state<2:\n",
    "                img_3ds = skimage.filters.gaussian(img_3d,[3,3,7],mode='constant',cval=1)            \n",
    "            elif state <5:\n",
    "                img_3ds = skimage.filters.gaussian(img_3d,[3,3,5],mode='constant',cval=1)            \n",
    "            else:\n",
    "                img_3ds = skimage.filters.gaussian(img_3d,[3,3,3],mode='constant',cval=1)            \n",
    "            img_3ds = (img_3ds+np.flip(img_3ds,axis=1))/2.0\n",
    "\n",
    "\n",
    "            odir_f = workdir+mid+\"/out/\"+str(cmp)+\"/\"+str(state)+'/filterd/'\n",
    "            os.makedirs(odir_f,exist_ok=True)\n",
    "            for z,dind in zip(range(len(bl_ids)),bl_ids):\n",
    "\n",
    "                nid = np.argmin(np.abs(bl_ids - dind))\n",
    "                nearest_bl = bl_ids[nid]\n",
    "\n",
    "                odir = workdir+mid+\"/out/\"+str(cmp)+\"/\"+str(state)+'/'\n",
    "                bl_img_1 = odir+\"/img/img_\"+str(nearest_bl)+\".nii.gz\"\n",
    "                assert(os.path.isfile(bl_img_1))\n",
    "                data_ref = nib.load(bl_img_1)\n",
    "\n",
    "                bl_img_1 = odir_f+\"/img_\"+str(nearest_bl)+\".nii.gz\"\n",
    "\n",
    "                img_t = img_3ds[...,z]\n",
    "\n",
    "                new_image = nib.Nifti1Image(img_t, affine=data_ref.affine)\n",
    "\n",
    "                new_image.header.set_xyzt_units(2)\n",
    "                new_image.header[\"dim\"][0] = 2\n",
    "                new_image.header[\"sform_code\"] = 1\n",
    "                new_image.header[\"pixdim\"][4:] = 0\n",
    "                nib.save(new_image,bl_img_1) \n",
    "            time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17254578-86b8-4611-a3ac-a01d817a3a58",
   "metadata": {},
   "source": [
    "### 8. Align segmented ISH images based on transforms from aligning raw ISH images in step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f25d80d-3fe4-4710-8b61-b4979e63a706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Create aligned ish seg\n",
    "\n",
    "\"\"\"\n",
    "Align segmented ISH gene images using the last transform that aligned raw ISH gene images to backlits in step #7.\n",
    "Takes as input segmented ISH gene images, aligned raw ISH gene images, and aligned backlit images (from steps #5,7,6).\n",
    "Uses ANTs Normalization Toolbox and slurm.\n",
    "To be moved to ANTsPy in the near future.\n",
    "\"\"\"\n",
    "\n",
    "def align_ish_seg(mid, cmp_ls):\n",
    "    \n",
    "    print(\"----- in 8 align_ish_seg for mid: \"+mid)\n",
    "    \n",
    "    ref_cmp = \"01_backlit\"\n",
    "    ref_cmp_dir = workdir+mid+\"/\"+ref_cmp+\"/\"\n",
    "    ref_files = glob.glob(ref_cmp_dir+\"/*.nii.gz\")\n",
    "    ref_files.sort()\n",
    "    ref_bl_ids = np.array([int(c.split(\"/\")[-1].replace(\"img_\",\"\").replace(\".nii.gz\",\"\")) for c in ref_files])\n",
    "\n",
    "    for cmp in cmp_ls:  \n",
    "        cmp_dir = workdir+mid+\"/\"+cmp+\"/\"\n",
    "        print('cmp_dir:',cmp_dir)\n",
    "\n",
    "        # get backlit ids that correspond to gene images\n",
    "        bf_dir = workdir+mid+\"/bf/\"  \n",
    "        backlit_files = glob.glob(cmp_dir+\"/img_*.nii.gz\")\n",
    "        backlit_files.sort()\n",
    "        bl_ids = np.array([int(c.split(\"/\")[-1].replace(\"img_\",\"\").replace(\".nii.gz\",\"\")) for c in backlit_files])\n",
    "\n",
    "        jobids=[]  \n",
    "\n",
    "        # create output directories for images\n",
    "        state=1\n",
    "        logfolder = workdir+mid+\"/logs/\"+str(cmp)+\"/\"+str(state)+'/'\n",
    "        os.makedirs(logfolder,exist_ok=True)\n",
    "        odir = workdir+mid+\"/out_seg/\"+str(cmp)+\"/\"+str(state)+'/'\n",
    "        print('odir: ', odir)\n",
    "        os.makedirs(odir,exist_ok=True)\n",
    "        odir_prev = workdir+mid+\"/out_seg/\"+str(cmp)+\"/\"+str(state-1)+'/'\n",
    "        dir_trafo = workdir+mid+\"/out/\"+str(cmp).split('_seg')[0]+\"/\"+str(2)+'/'\n",
    "        print('str(cmp): ',str(cmp))\n",
    "        print('dir_trafo: ',dir_trafo)\n",
    "\n",
    "        os.makedirs(odir+\"/trafo/\",exist_ok=True)\n",
    "        os.makedirs(odir+\"/img/\",exist_ok=True)\n",
    "\n",
    "        for z,dind in zip(range(len(bl_ids)),bl_ids):\n",
    "            bf_img = bf_dir+\"img_\"+str(dind)+\".nii.gz\"\n",
    "            assert(os.path.isfile(bf_img))\n",
    "\n",
    "            # find the bl_ids of the previous and next backlit slices.\n",
    "            # If the current slice is the FIRST slice, then the previous slice is set to be the same as the next slice.\n",
    "            # If the current slice is the LAST slice, then the next slice is set to be the same as the previous slice.\n",
    "            nid = np.argmin(np.abs(bl_ids - dind))      \n",
    "            if nid-1>=0:\n",
    "                prev_bl = bl_ids[nid-1]\n",
    "            else:\n",
    "                prev_bl = bl_ids[nid+1]\n",
    "            nearest_bl = bl_ids[nid]\n",
    "            if (nid+1) > (len(bl_ids)-1):\n",
    "                next_bl = prev_bl\n",
    "            else:\n",
    "                next_bl = bl_ids[nid+1]\n",
    "\n",
    "            nid = np.argmin(np.abs(ref_bl_ids - dind))  \n",
    "            nearest_ref = ref_bl_ids[nid]\n",
    "\n",
    "            FNAME  = \"img_\"+str(dind)\n",
    "\n",
    "            clear_output(wait=True)\n",
    "\n",
    "            # reference images are the last aligned backlit images (state 10)\n",
    "            odir_ref = workdir+mid+\"/out/01_backlit/10/\"\n",
    "            print('odir_ref: ',odir_ref)\n",
    "\n",
    "            bf_img = odir_ref+\"/filterd/\"+\"img_\"+str(nearest_ref)+\".nii.gz\"\n",
    "\n",
    "            bl_img_1 = cmp_dir+\"img_\"+str(nearest_bl)+\".nii.gz\"         # previous slice\n",
    "            bl_img_0 = cmp_dir+\"img_\"+str(prev_bl)+\".nii.gz\"            # slice to align\n",
    "            bl_img_2 = cmp_dir+\"img_\"+str(next_bl)+\".nii.gz\"\n",
    "            bl_avg = odir_ref+\"/filterd/img_\"+str(nearest_bl)+\".nii.gz\"\n",
    "            if z>len(bl_ids)//2:\n",
    "                REF_BL = bl_img_0\n",
    "            else:\n",
    "                REF_BL = bl_img_2\n",
    "\n",
    "            assert(os.path.isfile(bl_img_0))\n",
    "            assert(os.path.isfile(bl_img_1))\n",
    "            assert(os.path.isfile(bl_img_2))\n",
    "\n",
    "            PRETRAFO = dir_trafo+\"/trafo/trafo_\"+FNAME+\"Composite.h5\"\n",
    "            print('dir_trafo: ',dir_trafo)\n",
    "            print('FNAME: ',FNAME)\n",
    "            print('PRETRAFO: ', PRETRAFO)\n",
    "            SLURM_commands = [\"FIL=\"+bl_avg+\" REF_BL=\"+REF_BL+\" PRETRAFO=\"+PRETRAFO+\"  STATE=\"+str(state)+\"  ODIR=\"+odir+\"  FNAME=\"+FNAME+\"  BF=\"+bf_img+\" BL1=\"+bl_img_1+\"  BL0=\"+bl_img_0+\"  BL2=\"+bl_img_2+\" bash regme_gene_03_seg.sh;\"]#\n",
    "\n",
    "            jobid, success = slurm_tools.slurm_submit(SLURM_commands,\n",
    "                name = str(state)+\" \"+str(dind),\n",
    "                output = logfolder+'/log'+str(dind)+'.out',\n",
    "                mem = '16GB',\n",
    "                cores = '10',\n",
    "                nodelist = 'bigmem-02',                                      \n",
    "                )      \n",
    "\n",
    "            print(\"job number: \"+jobid)\n",
    "\n",
    "            if not success:\n",
    "                    print(\"could not submit jobs\")\n",
    "                    print(format(jobid))\n",
    "                    print(format(jobids))\n",
    "                    slurm_tools.killall(jobids)\n",
    "            jobids.append(int(jobid))\n",
    "\n",
    "        print(\"state \"+str(state))\n",
    "        slurm_tools.wait_for_jobs(jobids)\n",
    "\n",
    "\n",
    "        # to make filtered images/stack\n",
    "        time.sleep(5)\n",
    "        #state = 0\n",
    "        for z,dind in zip(range(len(bl_ids)),bl_ids):\n",
    "\n",
    "            nid = np.argmin(np.abs(bl_ids - dind))\n",
    "            nearest_bl = bl_ids[nid]\n",
    "\n",
    "            FNAME  = \"img_\"+str(dind)\n",
    "\n",
    "            odir = workdir+mid+\"/out_seg/\"+str(cmp)+\"/\"+str(state)+'/'\n",
    "            os.makedirs(odir,exist_ok=True)\n",
    "            #bl_img_1 = cmp_dir+\"img_\"+str(nearest_bl)+\".nii.gz\"\n",
    "            bl_img_1 = odir+\"/img/img_\"+str(nearest_bl)+\".nii.gz\"\n",
    "            assert(os.path.isfile(bl_img_1))\n",
    "\n",
    "            data = nib.load(bl_img_1)\n",
    "            if z == 0:\n",
    "                img_3d = np.zeros([data.shape[0],data.shape[1],len(bl_ids)])\n",
    "            img_3d[...,z] = data.get_fdata(dtype=np.float32)#*255\n",
    "\n",
    "        img_3ds = skimage.filters.gaussian(img_3d,[3,3,3],mode='constant',cval=1)            \n",
    "        img_3ds = (img_3ds+np.flip(img_3ds,axis=1))/2.0\n",
    "\n",
    "\n",
    "        odir_f = workdir+mid+\"/out_seg/\"+str(cmp)+\"/\"+str(state)+'/filterd/'\n",
    "        os.makedirs(odir_f,exist_ok=True)\n",
    "        for z,dind in zip(range(len(bl_ids)),bl_ids):\n",
    "\n",
    "            nid = np.argmin(np.abs(bl_ids - dind))\n",
    "            nearest_bl = bl_ids[nid]\n",
    "\n",
    "            odir = workdir+mid+\"/out_seg/\"+str(cmp)+\"/\"+str(state)+'/'\n",
    "            bl_img_1 = odir+\"/img/img_\"+str(nearest_bl)+\".nii.gz\"\n",
    "            assert(os.path.isfile(bl_img_1))\n",
    "            data_ref = nib.load(bl_img_1)\n",
    "\n",
    "            bl_img_1 = odir_f+\"/img_\"+str(nearest_bl)+\".nii.gz\"\n",
    "\n",
    "            #img_t = (np.minimum(np.maximum(img_3ds[...,z],0),255)).astype(np.uint8)\n",
    "            img_t = img_3ds[...,z]\n",
    "\n",
    "            new_image = nib.Nifti1Image(img_t, affine=data_ref.affine)\n",
    "\n",
    "            new_image.header.set_xyzt_units(2)\n",
    "            new_image.header[\"dim\"][0] = 2\n",
    "            new_image.header[\"sform_code\"] = 1\n",
    "            new_image.header[\"pixdim\"][4:] = 0\n",
    "            nib.save(new_image,bl_img_1) \n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2f34fc-bb08-44ca-adad-d909c6a68495",
   "metadata": {},
   "source": [
    "## Run 2d registration on a list of marmoset IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a05df8-ab99-4c5b-85b9-d65e8871aaf4",
   "metadata": {},
   "source": [
    "### Get a list of marmoset IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76903b0-9b69-415f-a5af-aeff699ad9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all marmoset folders with blockface images\n",
    "root = '/disk/charissa/shimogori_adult/'\n",
    "marm_ls = []\n",
    "for marm_dir in os.listdir(root):\n",
    "    if os.path.isdir(os.path.join(root, marm_dir)) and 'R0' in marm_dir:\n",
    "        if os.path.exists(os.path.join(root,marm_dir)+'/img2d/blockface_raw/'):\n",
    "            marm_ls.append(marm_dir)\n",
    "        \n",
    "marm_ls.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca906dc0-ae79-4630-a34a-902d6a0e8251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call everything, loop try the rest of the data\n",
    "db = '/disk/charissa/shimogori_adult/'\n",
    "workdir = '/disk/charissa/ISH_reg_pipeline/data/'\n",
    "target_res = 25\n",
    "mu_bl = 3.12\n",
    "\n",
    "for d in range(len(marm_ls)):\n",
    "    \n",
    "    mid = marm_ls[d]\n",
    "    print(mid)\n",
    "\n",
    "    mu_bl = 3.12\n",
    "    mu_bf = 28.72\n",
    "\n",
    "    print(\"mu bl:\",mu_bl)\n",
    "    print(\"mu bf:\",mu_bf)\n",
    "\n",
    "    os.makedirs(workdir+mid+\"/bf/\",exist_ok=True)\n",
    "\n",
    "    sdir = db+mid+\"/img2d/\"\n",
    "    bf_files = glob.glob(sdir+\"/blockface_raw2/*.png\")\n",
    "    bf_files.sort()\n",
    "    \n",
    "    bf_files_, img_mip = make_bf_mip(bf_files)  # 1\n",
    "    img_3D = create_bf_3d_stack(mu_bf, bf_files_, img_mip)  # 2\n",
    "    filter_write_bf(img_3D, target_res, bf_files_, mid)  # 3\n",
    "    create_bl_gene_niis(mid)  # 4\n",
    "    create_geneseg_niis(mid)  # 5\n",
    "    \n",
    "\n",
    "    cmp_ls_all = os.listdir(workdir+mid)\n",
    "    cmp_ls_raw = [m for m in cmp_ls_all if 'gene' in m and 'backlit' not in m and 'seg' not in m]\n",
    "    cmp_ls_seg = [m for m in cmp_ls_all if 'gene_seg' in m and 'backlit' not in m]\n",
    "    \n",
    "    align_bl(mid)  # 6\n",
    "    align_ish(mid,cmp_ls_raw)  # 7\n",
    "    align_ish_seg(mid,cmp_ls_seg)  # 8\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cluster]",
   "language": "python",
   "name": "conda-env-cluster-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
